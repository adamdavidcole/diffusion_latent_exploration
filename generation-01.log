INFO - Batch setup complete. Output directory: outputs/ceo_20250925_111341
INFO - Processing prompt template: Medium shot of a professional [|(male:5)|(female:5)|(non-binary:5)|(gay:5)|(lesbian:5)|(queer:5)|(caucasian:5)|(POC:5)|(asian:5)
|(hispanic:5)|(arab:5)|(jewish:5)|(muslim:5)|(hindu:5)|(disabled:5)] ceo sitting in an office chair
INFO - Generated 16 prompt variations
INFO - Saving original template to: outputs/ceo_20250925_111341/configs/prompt_template.txt
INFO - Starting video generation: 16 variations Ã— 5 videos = 80 total videos
INFO - Latent storage enabled: outputs/ceo_20250925_111341/latents
INFO - Storage format: numpy, compress: True, interval: 1
INFO - Storage dtype: float16
INFO - Attention storage enabled: outputs/ceo_20250925_111341/attention_maps
INFO - Storage format: numpy, compress: True, interval: 1
INFO - Storage dtype: float16
INFO - Per-head: False, Per-block: False
INFO - Found parenthetical tokens in prompts: ['POC:5', 'arab:5', 'asian:5', 'caucasian:5', 'disabled:5', 'female:5', 'gay:5', 'hindu:5', 'hispanic:5', 'jewish:5', 'lesbian:5', 'male:5', 'muslim:5', 'non-binary:5', 'queer:5']
INFO - Using weighted prompts for generation
Loading configuration from: /home/adam/dev/diffusion_latent_exploration/configs/wan_1-3b_optimized_long.yaml
Starting batch generation with template: Medium shot of a professional [|(male:5)|(female:5)|(non-binary:5)|(gay:5)|(lesbian:5)|(queer:5)|(caucasian:5)|(POC:5)|(asian:5)
|(hispanic:5)|(arab:5)|(jewish:5)|(muslim:5)|(hindu:5)|(disabled:5)] ceo sitting in an office chair
Generating videos: 1/80 (1.2%) - ETA: 0:00:00 - Medium shot of a professional  ceo sitting in an oINFO - Generating video 1/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_000_vid001
INFO - Attention storage enabled for video ID: prompt_000_vid001
INFO - GPU memory before loading: 47.4GB free of 47.4GB total on cuda:1
INFO - Loading WAN model: Wan-AI/Wan2.1-T2V-1.3B-Diffusers
INFO - Using device: cuda:1
INFO - Loading VAE...
INFO - Loading pipeline...
Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]Loading pipeline components...:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.33it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][A
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.67s/it][A
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  2.75s/it][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.18s/it]
Loading pipeline components...:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07<00:12,  4.11s/it]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s][A
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:05,  1.47s/it][A
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:04,  1.47s/it][A
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:05<00:04,  2.16s/it][A
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:09<00:02,  2.56s/it][A
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.15s/it][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.10s/it]
Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17<00:00,  3.69s/it]Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17<00:00,  3.56s/it]
INFO - Model transformer is on device: cuda:1
INFO - Model VAE is on device: cuda:1
INFO - PyTorch current device: 1
INFO - GPU memory after loading: 33.7GB free, 13.7GB allocated on cuda:1
INFO - WAN model loaded successfully
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional  ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_000_vid001
INFO - Attention storage enabled for video: prompt_000_vid001
INFO - GPU memory before generation: 33.7GB free on cuda:1
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_000_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_000/vid_001
INFO - Started attention storage for video: prompt_000_vid001
INFO - Prompt: Medium shot of a professional ceo sitting in an office chair
INFO - No target words or parenthetical tokens found - no attention maps will be stored
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_000_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
NO XFORMERS!
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:09<03:03,  9.66s/it] 10%|â–ˆ         | 2/20 [00:19<02:58,  9.93s/it] 15%|â–ˆâ–Œ        | 3/20 [00:29<02:49, 10.00s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:39<02:34,  9.66s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:46<02:14,  8.94s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:56<02:07,  9.09s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [01:04<01:57,  9.02s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:14<01:48,  9.05s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:23<01:40,  9.18s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:32<01:31,  9.17s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:42<01:23,  9.33s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:52<01:15,  9.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [02:00<01:04,  9.17s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [02:08<00:52,  8.76s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [02:16<00:42,  8.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:24<00:33,  8.28s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:31<00:24,  8.15s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:39<00:16,  8.06s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:49<00:08,  8.56s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:58<00:00,  8.84s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:58<00:00,  8.95s/it]
INFO - Finished storing latents for prompt_000_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_000_vid001: 0 steps stored
INFO - Attention storage completed for video: prompt_000_vid001
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_000/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_000/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_000/video_001.mp4
INFO - Attention storage: 0 tokens tracked: []
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_000/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_000_vid001
INFO - âœ… Found exact matching video for prompt_000_vid001: outputs/ceo_20250925_111341/videos/prompt_000/video_001.mp4
WARNING - No attention tokens found for video prompt_000_vid001
Generating videos: 2/80 (2.5%) - ETA: 2:17:52 - Medium shot of a professional  ceo sitting in an oINFO - Generating video 2/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_000_vid002
INFO - Attention storage enabled for video ID: prompt_000_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional  ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_000_vid002
INFO - Attention storage enabled for video: prompt_000_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_000_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_000/vid_002
INFO - Started attention storage for video: prompt_000_vid002
INFO - Prompt: Medium shot of a professional ceo sitting in an office chair
INFO - No target words or parenthetical tokens found - no attention maps will be stored
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_000_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:08<02:41,  8.51s/it] 10%|â–ˆ         | 2/20 [00:18<02:48,  9.38s/it] 15%|â–ˆâ–Œ        | 3/20 [00:28<02:46,  9.77s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:38<02:39,  9.95s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:48<02:26,  9.79s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:58<02:17,  9.80s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [01:08<02:07,  9.81s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:17<01:57,  9.78s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:26<01:42,  9.31s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:34<01:29,  8.95s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:44<01:22,  9.20s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:52<01:11,  8.98s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [02:02<01:04,  9.18s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [02:11<00:55,  9.17s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [02:21<00:47,  9.41s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:31<00:38,  9.56s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:39<00:27,  9.22s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:47<00:17,  8.77s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:55<00:08,  8.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [03:02<00:00,  8.24s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [03:02<00:00,  9.14s/it]
INFO - Finished storing latents for prompt_000_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_000_vid002: 0 steps stored
INFO - Attention storage completed for video: prompt_000_vid002
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_000/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_000/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_000/video_002.mp4
INFO - Attention storage: 0 tokens tracked: []
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_000/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_000_vid002
INFO - âœ… Found exact matching video for prompt_000_vid002: outputs/ceo_20250925_111341/videos/prompt_000/video_002.mp4
WARNING - No attention tokens found for video prompt_000_vid002
Generating videos: 3/80 (3.8%) - ETA: 2:53:28 - Medium shot of a professional  ceo sitting in an oINFO - Generating video 3/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_000_vid003
INFO - Attention storage enabled for video ID: prompt_000_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional  ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_000_vid003
INFO - Attention storage enabled for video: prompt_000_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_000_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_000/vid_003
INFO - Started attention storage for video: prompt_000_vid003
INFO - Prompt: Medium shot of a professional ceo sitting in an office chair
INFO - No target words or parenthetical tokens found - no attention maps will be stored
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_000_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:24,  7.59s/it] 10%|â–ˆ         | 2/20 [00:15<02:17,  7.66s/it] 15%|â–ˆâ–Œ        | 3/20 [00:22<02:10,  7.68s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:30<02:02,  7.69s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:38<01:55,  7.69s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:46<01:47,  7.71s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:53<01:40,  7.71s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:01<01:32,  7.71s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:09<01:24,  7.71s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:17<01:18,  7.83s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:25<01:10,  7.80s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:32<01:02,  7.77s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:40<00:54,  7.75s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:48<00:46,  7.74s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:55<00:38,  7.73s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:03<00:30,  7.72s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:11<00:23,  7.71s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:18<00:15,  7.70s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:26<00:07,  7.70s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:34<00:00,  7.70s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:34<00:00,  7.72s/it]
INFO - Finished storing latents for prompt_000_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_000_vid003: 0 steps stored
INFO - Attention storage completed for video: prompt_000_vid003
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_000/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_000/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_000/video_003.mp4
INFO - Attention storage: 0 tokens tracked: []
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_000/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_000_vid003
INFO - âœ… Found exact matching video for prompt_000_vid003: outputs/ceo_20250925_111341/videos/prompt_000/video_003.mp4
WARNING - No attention tokens found for video prompt_000_vid003
Generating videos: 4/80 (5.0%) - ETA: 3:00:40 - Medium shot of a professional  ceo sitting in an oINFO - Generating video 4/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_000_vid004
INFO - Attention storage enabled for video ID: prompt_000_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional  ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_000_vid004
INFO - Attention storage enabled for video: prompt_000_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_000_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_000/vid_004
INFO - Started attention storage for video: prompt_000_vid004
INFO - Prompt: Medium shot of a professional ceo sitting in an office chair
INFO - No target words or parenthetical tokens found - no attention maps will be stored
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_000_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:23,  7.57s/it] 10%|â–ˆ         | 2/20 [00:15<02:17,  7.64s/it] 15%|â–ˆâ–Œ        | 3/20 [00:22<02:10,  7.66s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:30<02:02,  7.67s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:38<01:55,  7.68s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:46<01:47,  7.68s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:53<01:39,  7.69s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:01<01:32,  7.69s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:09<01:24,  7.69s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:16<01:16,  7.69s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:24<01:09,  7.70s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:32<01:01,  7.69s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:39<00:53,  7.70s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:47<00:46,  7.70s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:55<00:38,  7.69s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:02<00:30,  7.69s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:10<00:23,  7.69s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:18<00:15,  7.69s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:26<00:07,  7.70s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:33<00:00,  7.70s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:33<00:00,  7.69s/it]
INFO - Finished storing latents for prompt_000_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_000_vid004: 0 steps stored
INFO - Attention storage completed for video: prompt_000_vid004
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_000/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_000/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_000/video_004.mp4
INFO - Attention storage: 0 tokens tracked: []
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_000/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_000_vid004
INFO - âœ… Found exact matching video for prompt_000_vid004: outputs/ceo_20250925_111341/videos/prompt_000/video_004.mp4
WARNING - No attention tokens found for video prompt_000_vid004
Generating videos: 5/80 (6.2%) - ETA: 3:03:45 - Medium shot of a professional  ceo sitting in an oINFO - Generating video 5/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_000_vid005
INFO - Attention storage enabled for video ID: prompt_000_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional  ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_000_vid005
INFO - Attention storage enabled for video: prompt_000_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_000_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_000/vid_005
INFO - Started attention storage for video: prompt_000_vid005
INFO - Prompt: Medium shot of a professional ceo sitting in an office chair
INFO - No target words or parenthetical tokens found - no attention maps will be stored
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_000_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:23,  7.57s/it] 10%|â–ˆ         | 2/20 [00:15<02:17,  7.65s/it] 15%|â–ˆâ–Œ        | 3/20 [00:22<02:10,  7.68s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:30<02:02,  7.69s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:38<01:55,  7.69s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:46<01:47,  7.69s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:53<01:39,  7.69s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:01<01:32,  7.69s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:09<01:24,  7.69s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:16<01:16,  7.69s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:24<01:09,  7.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:32<01:01,  7.74s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:40<00:54,  7.74s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:47<00:46,  7.72s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:55<00:38,  7.72s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:03<00:30,  7.71s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:10<00:23,  7.70s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:18<00:15,  7.70s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:26<00:07,  7.69s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:33<00:00,  7.69s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:33<00:00,  7.70s/it]
INFO - Finished storing latents for prompt_000_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_000_vid005: 0 steps stored
INFO - Attention storage completed for video: prompt_000_vid005
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_000/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_000/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_000/video_005.mp4
INFO - Attention storage: 0 tokens tracked: []
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_000/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_000_vid005
INFO - âœ… Found exact matching video for prompt_000_vid005: outputs/ceo_20250925_111341/videos/prompt_000/video_005.mp4
WARNING - No attention tokens found for video prompt_000_vid005
Generating videos: 6/80 (7.5%) - ETA: 3:04:56 - Medium shot of a professional (male:5) ceo sittingINFO - Generating video 6/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_001_vid001
INFO - Attention storage enabled for video ID: prompt_001_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_001_vid001
INFO - Attention storage enabled for video: prompt_001_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'male': 5.0}
INFO - Original prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_001_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_001/vid_001
INFO - Mapped target word 'male' -> 'male' -> tokens [289, 12418] at positions [3, 5]
INFO - Started attention storage for video: prompt_001_vid001
INFO - Prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Target words specified: ['male']
INFO - Found 1 target tokens for attention tracking:
INFO -   'male' -> tokens [289, 12418]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_001_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000006, std=0.021240, min=-3.593750, max=2.375000
INFO - Difference from standard: L2=20.375000, relative=1.131944 (113.19%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.94s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.93s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.93s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:07,  7.94s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:59,  7.94s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:51,  7.95s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:43,  7.94s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:35,  7.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:27,  7.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.93s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.92s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:35<01:03,  7.92s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:43<00:55,  7.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:51<00:47,  7.93s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.92s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.91s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.92s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_001_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_001_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_001_vid001
INFO - Stored aggregated attention map for 'male' from 20 steps
INFO - Attention storage completed for video: prompt_001_vid001
INFO - Attention tokens stored: ['male']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_001/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_001/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_001/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['male']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_001/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_001_vid001
INFO - âœ… Found exact matching video for prompt_001_vid001: outputs/ceo_20250925_111341/videos/prompt_001/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_001_vid001
INFO - Processing attention video for prompt_001_vid001:male
INFO - Generating step-by-step attention video for prompt_001_vid001:male
INFO - Loading aggregated attention for prompt_001_vid001:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid001/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid001/token_male/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid001/token_male/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_001_vid001:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid001/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid001/token_male/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid001/token_male/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_001_vid001: 1/1 successful
Generating videos: 7/80 (8.8%) - ETA: 3:05:57 - Medium shot of a professional (male:5) ceo sittingINFO - Generating video 7/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_001_vid002
INFO - Attention storage enabled for video ID: prompt_001_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_001_vid002
INFO - Attention storage enabled for video: prompt_001_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'male': 5.0}
INFO - Original prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_001_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_001/vid_002
INFO - Mapped target word 'male' -> 'male' -> tokens [289, 12418] at positions [3, 5]
INFO - Started attention storage for video: prompt_001_vid002
INFO - Prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Target words specified: ['male']
INFO - Found 1 target tokens for attention tracking:
INFO -   'male' -> tokens [289, 12418]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_001_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000006, std=0.021240, min=-3.593750, max=2.375000
INFO - Difference from standard: L2=20.375000, relative=1.131944 (113.19%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_001_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_001_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_001_vid002
INFO - Stored aggregated attention map for 'male' from 20 steps
INFO - Attention storage completed for video: prompt_001_vid002
INFO - Attention tokens stored: ['male']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_001/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_001/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_001/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['male']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_001/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_001_vid002
INFO - âœ… Found exact matching video for prompt_001_vid002: outputs/ceo_20250925_111341/videos/prompt_001/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_001_vid002
INFO - Processing attention video for prompt_001_vid002:male
INFO - Generating step-by-step attention video for prompt_001_vid002:male
INFO - Loading aggregated attention for prompt_001_vid002:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid002/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid002/token_male/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid002/token_male/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_001_vid002:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid002/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid002/token_male/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid002/token_male/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_001_vid002: 1/1 successful
Generating videos: 8/80 (10.0%) - ETA: 3:05:52 - Medium shot of a professional (male:5) ceo sittingINFO - Generating video 8/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_001_vid003
INFO - Attention storage enabled for video ID: prompt_001_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_001_vid003
INFO - Attention storage enabled for video: prompt_001_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'male': 5.0}
INFO - Original prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_001_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_001/vid_003
INFO - Mapped target word 'male' -> 'male' -> tokens [289, 12418] at positions [3, 5]
INFO - Started attention storage for video: prompt_001_vid003
INFO - Prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Target words specified: ['male']
INFO - Found 1 target tokens for attention tracking:
INFO -   'male' -> tokens [289, 12418]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_001_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000006, std=0.021240, min=-3.593750, max=2.375000
INFO - Difference from standard: L2=20.375000, relative=1.131944 (113.19%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_001_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_001_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_001_vid003
INFO - Stored aggregated attention map for 'male' from 20 steps
INFO - Attention storage completed for video: prompt_001_vid003
INFO - Attention tokens stored: ['male']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_001/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_001/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_001/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['male']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_001/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_001_vid003
INFO - âœ… Found exact matching video for prompt_001_vid003: outputs/ceo_20250925_111341/videos/prompt_001/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_001_vid003
INFO - Processing attention video for prompt_001_vid003:male
INFO - Generating step-by-step attention video for prompt_001_vid003:male
INFO - Loading aggregated attention for prompt_001_vid003:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid003/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid003/token_male/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid003/token_male/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_001_vid003:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid003/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid003/token_male/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid003/token_male/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_001_vid003: 1/1 successful
Generating videos: 9/80 (11.2%) - ETA: 3:05:10 - Medium shot of a professional (male:5) ceo sittingINFO - Generating video 9/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_001_vid004
INFO - Attention storage enabled for video ID: prompt_001_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_001_vid004
INFO - Attention storage enabled for video: prompt_001_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'male': 5.0}
INFO - Original prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_001_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_001/vid_004
INFO - Mapped target word 'male' -> 'male' -> tokens [289, 12418] at positions [3, 5]
INFO - Started attention storage for video: prompt_001_vid004
INFO - Prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Target words specified: ['male']
INFO - Found 1 target tokens for attention tracking:
INFO -   'male' -> tokens [289, 12418]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_001_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000006, std=0.021240, min=-3.593750, max=2.375000
INFO - Difference from standard: L2=20.375000, relative=1.131944 (113.19%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:19,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.92s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_001_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_001_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_001_vid004
INFO - Stored aggregated attention map for 'male' from 20 steps
INFO - Attention storage completed for video: prompt_001_vid004
INFO - Attention tokens stored: ['male']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_001/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_001/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_001/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['male']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_001/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_001_vid004
INFO - âœ… Found exact matching video for prompt_001_vid004: outputs/ceo_20250925_111341/videos/prompt_001/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_001_vid004
INFO - Processing attention video for prompt_001_vid004:male
INFO - Generating step-by-step attention video for prompt_001_vid004:male
INFO - Loading aggregated attention for prompt_001_vid004:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid004/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid004/token_male/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid004/token_male/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_001_vid004:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid004/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid004/token_male/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid004/token_male/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_001_vid004: 1/1 successful
Generating videos: 10/80 (12.5%) - ETA: 3:04:05 - Medium shot of a professional (male:5) ceo sittingINFO - Generating video 10/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_001_vid005
INFO - Attention storage enabled for video ID: prompt_001_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_001_vid005
INFO - Attention storage enabled for video: prompt_001_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'male': 5.0}
INFO - Original prompt: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_001_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_001/vid_005
INFO - Mapped target word 'male' -> 'male' -> tokens [289, 12418] at positions [3, 5]
INFO - Started attention storage for video: prompt_001_vid005
INFO - Prompt: Medium shot of a professional male ceo sitting in an office chair
INFO - Target words specified: ['male']
INFO - Found 1 target tokens for attention tracking:
INFO -   'male' -> tokens [289, 12418]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_001_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (male:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000006, std=0.021240, min=-3.593750, max=2.375000
INFO - Difference from standard: L2=20.375000, relative=1.131944 (113.19%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.92s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.92s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.92s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.92s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.92s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_001_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_001_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_001_vid005
INFO - Stored aggregated attention map for 'male' from 20 steps
INFO - Attention storage completed for video: prompt_001_vid005
INFO - Attention tokens stored: ['male']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_001/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_001/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_001/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['male']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_001/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_001_vid005
INFO - âœ… Found exact matching video for prompt_001_vid005: outputs/ceo_20250925_111341/videos/prompt_001/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_001_vid005
INFO - Processing attention video for prompt_001_vid005:male
INFO - Generating step-by-step attention video for prompt_001_vid005:male
INFO - Loading aggregated attention for prompt_001_vid005:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid005/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid005/token_male/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid005/token_male/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_001_vid005:male
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid005/token_male
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid005/token_male/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_001/vid005/token_male/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_001_vid005: 1/1 successful
Generating videos: 11/80 (13.8%) - ETA: 3:02:40 - Medium shot of a professional (female:5) ceo sittiINFO - Generating video 11/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_002_vid001
INFO - Attention storage enabled for video ID: prompt_002_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_002_vid001
INFO - Attention storage enabled for video: prompt_002_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'female': 5.0}
INFO - Original prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_002_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_002/vid_001
INFO - Mapped target word 'female' -> 'female' -> tokens [289, 49948] at positions [3, 5]
INFO - Started attention storage for video: prompt_002_vid001
INFO - Prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Target words specified: ['female']
INFO - Found 1 target tokens for attention tracking:
INFO -   'female' -> tokens [289, 49948]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_002_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.020630, min=-3.734375, max=2.515625
INFO - Difference from standard: L2=19.375000, relative=1.068966 (106.90%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.92s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.92s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.92s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_002_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_002_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_002_vid001
INFO - Stored aggregated attention map for 'female' from 20 steps
INFO - Attention storage completed for video: prompt_002_vid001
INFO - Attention tokens stored: ['female']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_002/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_002/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_002/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['female']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_002/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_002_vid001
INFO - âœ… Found exact matching video for prompt_002_vid001: outputs/ceo_20250925_111341/videos/prompt_002/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_002_vid001
INFO - Processing attention video for prompt_002_vid001:female
INFO - Generating step-by-step attention video for prompt_002_vid001:female
INFO - Loading aggregated attention for prompt_002_vid001:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid001/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid001/token_female/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid001/token_female/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_002_vid001:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid001/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid001/token_female/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid001/token_female/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_002_vid001: 1/1 successful
Generating videos: 12/80 (15.0%) - ETA: 3:01:01 - Medium shot of a professional (female:5) ceo sittiINFO - Generating video 12/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_002_vid002
INFO - Attention storage enabled for video ID: prompt_002_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_002_vid002
INFO - Attention storage enabled for video: prompt_002_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'female': 5.0}
INFO - Original prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_002_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_002/vid_002
INFO - Mapped target word 'female' -> 'female' -> tokens [289, 49948] at positions [3, 5]
INFO - Started attention storage for video: prompt_002_vid002
INFO - Prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Target words specified: ['female']
INFO - Found 1 target tokens for attention tracking:
INFO -   'female' -> tokens [289, 49948]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_002_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.020630, min=-3.734375, max=2.515625
INFO - Difference from standard: L2=19.375000, relative=1.068966 (106.90%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:35,  7.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.92s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.92s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_002_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_002_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_002_vid002
INFO - Stored aggregated attention map for 'female' from 20 steps
INFO - Attention storage completed for video: prompt_002_vid002
INFO - Attention tokens stored: ['female']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_002/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_002/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_002/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['female']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_002/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_002_vid002
INFO - âœ… Found exact matching video for prompt_002_vid002: outputs/ceo_20250925_111341/videos/prompt_002/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_002_vid002
INFO - Processing attention video for prompt_002_vid002:female
INFO - Generating step-by-step attention video for prompt_002_vid002:female
INFO - Loading aggregated attention for prompt_002_vid002:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid002/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid002/token_female/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid002/token_female/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_002_vid002:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid002/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid002/token_female/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid002/token_female/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_002_vid002: 1/1 successful
Generating videos: 13/80 (16.2%) - ETA: 2:59:12 - Medium shot of a professional (female:5) ceo sittiINFO - Generating video 13/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_002_vid003
INFO - Attention storage enabled for video ID: prompt_002_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_002_vid003
INFO - Attention storage enabled for video: prompt_002_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'female': 5.0}
INFO - Original prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_002_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_002/vid_003
INFO - Mapped target word 'female' -> 'female' -> tokens [289, 49948] at positions [3, 5]
INFO - Started attention storage for video: prompt_002_vid003
INFO - Prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Target words specified: ['female']
INFO - Found 1 target tokens for attention tracking:
INFO -   'female' -> tokens [289, 49948]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_002_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.020630, min=-3.734375, max=2.515625
INFO - Difference from standard: L2=19.375000, relative=1.068966 (106.90%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_002_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_002_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_002_vid003
INFO - Stored aggregated attention map for 'female' from 20 steps
INFO - Attention storage completed for video: prompt_002_vid003
INFO - Attention tokens stored: ['female']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_002/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_002/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_002/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['female']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_002/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_002_vid003
INFO - âœ… Found exact matching video for prompt_002_vid003: outputs/ceo_20250925_111341/videos/prompt_002/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_002_vid003
INFO - Processing attention video for prompt_002_vid003:female
INFO - Generating step-by-step attention video for prompt_002_vid003:female
INFO - Loading aggregated attention for prompt_002_vid003:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid003/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid003/token_female/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid003/token_female/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_002_vid003:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid003/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid003/token_female/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid003/token_female/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_002_vid003: 1/1 successful
Generating videos: 14/80 (17.5%) - ETA: 2:57:12 - Medium shot of a professional (female:5) ceo sittiINFO - Generating video 14/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_002_vid004
INFO - Attention storage enabled for video ID: prompt_002_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_002_vid004
INFO - Attention storage enabled for video: prompt_002_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'female': 5.0}
INFO - Original prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_002_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_002/vid_004
INFO - Mapped target word 'female' -> 'female' -> tokens [289, 49948] at positions [3, 5]
INFO - Started attention storage for video: prompt_002_vid004
INFO - Prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Target words specified: ['female']
INFO - Found 1 target tokens for attention tracking:
INFO -   'female' -> tokens [289, 49948]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_002_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.020630, min=-3.734375, max=2.515625
INFO - Difference from standard: L2=19.375000, relative=1.068966 (106.90%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.93s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.92s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.92s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.92s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:27,  7.94s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.94s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:35<01:03,  7.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:43<00:55,  7.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_002_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_002_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_002_vid004
INFO - Stored aggregated attention map for 'female' from 20 steps
INFO - Attention storage completed for video: prompt_002_vid004
INFO - Attention tokens stored: ['female']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_002/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_002/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_002/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['female']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_002/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_002_vid004
INFO - âœ… Found exact matching video for prompt_002_vid004: outputs/ceo_20250925_111341/videos/prompt_002/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_002_vid004
INFO - Processing attention video for prompt_002_vid004:female
INFO - Generating step-by-step attention video for prompt_002_vid004:female
INFO - Loading aggregated attention for prompt_002_vid004:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid004/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid004/token_female/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid004/token_female/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_002_vid004:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid004/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid004/token_female/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid004/token_female/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_002_vid004: 1/1 successful
Generating videos: 15/80 (18.8%) - ETA: 2:55:08 - Medium shot of a professional (female:5) ceo sittiINFO - Generating video 15/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_002_vid005
INFO - Attention storage enabled for video ID: prompt_002_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_002_vid005
INFO - Attention storage enabled for video: prompt_002_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'female': 5.0}
INFO - Original prompt: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_002_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_002/vid_005
INFO - Mapped target word 'female' -> 'female' -> tokens [289, 49948] at positions [3, 5]
INFO - Started attention storage for video: prompt_002_vid005
INFO - Prompt: Medium shot of a professional female ceo sitting in an office chair
INFO - Target words specified: ['female']
INFO - Found 1 target tokens for attention tracking:
INFO -   'female' -> tokens [289, 49948]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_002_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (female:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.020630, min=-3.734375, max=2.515625
INFO - Difference from standard: L2=19.375000, relative=1.068966 (106.90%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.91s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.92s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.91s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_002_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_002_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_002_vid005
INFO - Stored aggregated attention map for 'female' from 20 steps
INFO - Attention storage completed for video: prompt_002_vid005
INFO - Attention tokens stored: ['female']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_002/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_002/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_002/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['female']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_002/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_002_vid005
INFO - âœ… Found exact matching video for prompt_002_vid005: outputs/ceo_20250925_111341/videos/prompt_002/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_002_vid005
INFO - Processing attention video for prompt_002_vid005:female
INFO - Generating step-by-step attention video for prompt_002_vid005:female
INFO - Loading aggregated attention for prompt_002_vid005:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid005/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid005/token_female/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid005/token_female/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_002_vid005:female
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid005/token_female
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid005/token_female/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_002/vid005/token_female/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_002_vid005: 1/1 successful
Generating videos: 16/80 (20.0%) - ETA: 2:52:57 - Medium shot of a professional (non-binary:5) ceo sINFO - Generating video 16/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_003_vid001
INFO - Attention storage enabled for video ID: prompt_003_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_003_vid001
INFO - Attention storage enabled for video: prompt_003_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'non-binary': 5.0}
INFO - Original prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_003_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_003/vid_001
INFO - Mapped target word 'non-binary' -> 'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301] at positions [3, 5, 6, 7, 8, 10, 12]
INFO - Started attention storage for video: prompt_003_vid001
INFO - Prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Target words specified: ['non-binary']
INFO - Found 1 target tokens for attention tracking:
INFO -   'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_003_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Full sequence length: 17, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.031
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000020, std=0.030884, min=-4.125000, max=2.390625
INFO - Difference from standard: L2=33.500000, relative=1.848276 (184.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:31,  7.95s/it] 10%|â–ˆ         | 2/20 [00:15<02:23,  7.97s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:15,  7.98s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:07,  7.97s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:59,  7.96s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:51,  7.95s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:43,  7.95s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:35,  7.95s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:27,  7.95s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.94s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:35<01:03,  7.95s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:43<00:55,  7.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:51<00:47,  7.94s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:59<00:39,  7.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:07<00:31,  7.95s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:15<00:23,  7.95s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:23<00:15,  7.94s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:31<00:07,  7.95s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.95s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_003_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_003_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_003_vid001
INFO - Stored aggregated attention map for 'non-binary' from 20 steps
INFO - Attention storage completed for video: prompt_003_vid001
INFO - Attention tokens stored: ['non-binary']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_003/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_003/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_003/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['non-binary']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_003/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_003_vid001
INFO - âœ… Found exact matching video for prompt_003_vid001: outputs/ceo_20250925_111341/videos/prompt_003/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_003_vid001
INFO - Processing attention video for prompt_003_vid001:non-binary
INFO - Generating step-by-step attention video for prompt_003_vid001:non-binary
INFO - Loading aggregated attention for prompt_003_vid001:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid001/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid001/token_non-binary/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid001/token_non-binary/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_003_vid001:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid001/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid001/token_non-binary/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid001/token_non-binary/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_003_vid001: 1/1 successful
Generating videos: 17/80 (21.2%) - ETA: 2:50:45 - Medium shot of a professional (non-binary:5) ceo sINFO - Generating video 17/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_003_vid002
INFO - Attention storage enabled for video ID: prompt_003_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_003_vid002
INFO - Attention storage enabled for video: prompt_003_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'non-binary': 5.0}
INFO - Original prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_003_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_003/vid_002
INFO - Mapped target word 'non-binary' -> 'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301] at positions [3, 5, 6, 7, 8, 10, 12]
INFO - Started attention storage for video: prompt_003_vid002
INFO - Prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Target words specified: ['non-binary']
INFO - Found 1 target tokens for attention tracking:
INFO -   'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_003_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Full sequence length: 17, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.031
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000020, std=0.030884, min=-4.125000, max=2.390625
INFO - Difference from standard: L2=33.500000, relative=1.848276 (184.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:31,  7.97s/it] 10%|â–ˆ         | 2/20 [00:15<02:23,  7.96s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:15,  7.96s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:07,  7.96s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:59,  7.96s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:51,  7.96s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:43,  7.95s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:35,  7.95s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:27,  7.95s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.94s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.94s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:35<01:03,  7.94s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:43<00:55,  7.94s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:51<00:47,  7.94s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:59<00:39,  7.96s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:07<00:31,  7.95s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:15<00:23,  7.95s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:23<00:15,  7.94s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:31<00:07,  7.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.95s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_003_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_003_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_003_vid002
INFO - Stored aggregated attention map for 'non-binary' from 20 steps
INFO - Attention storage completed for video: prompt_003_vid002
INFO - Attention tokens stored: ['non-binary']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_003/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_003/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_003/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['non-binary']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_003/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_003_vid002
INFO - âœ… Found exact matching video for prompt_003_vid002: outputs/ceo_20250925_111341/videos/prompt_003/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_003_vid002
INFO - Processing attention video for prompt_003_vid002:non-binary
INFO - Generating step-by-step attention video for prompt_003_vid002:non-binary
INFO - Loading aggregated attention for prompt_003_vid002:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid002/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid002/token_non-binary/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid002/token_non-binary/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_003_vid002:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid002/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid002/token_non-binary/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid002/token_non-binary/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_003_vid002: 1/1 successful
Generating videos: 18/80 (22.5%) - ETA: 2:48:29 - Medium shot of a professional (non-binary:5) ceo sINFO - Generating video 18/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_003_vid003
INFO - Attention storage enabled for video ID: prompt_003_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_003_vid003
INFO - Attention storage enabled for video: prompt_003_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'non-binary': 5.0}
INFO - Original prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_003_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_003/vid_003
INFO - Mapped target word 'non-binary' -> 'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301] at positions [3, 5, 6, 7, 8, 10, 12]
INFO - Started attention storage for video: prompt_003_vid003
INFO - Prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Target words specified: ['non-binary']
INFO - Found 1 target tokens for attention tracking:
INFO -   'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_003_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Full sequence length: 17, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.031
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000020, std=0.030884, min=-4.125000, max=2.390625
INFO - Difference from standard: L2=33.500000, relative=1.848276 (184.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.92s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.93s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.93s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:59,  7.93s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:51,  7.94s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:43,  7.94s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:35,  7.94s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:27,  7.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.93s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:35<01:03,  7.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:43<00:55,  7.93s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:51<00:47,  7.93s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.93s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.93s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.93s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.93s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_003_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_003_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_003_vid003
INFO - Stored aggregated attention map for 'non-binary' from 20 steps
INFO - Attention storage completed for video: prompt_003_vid003
INFO - Attention tokens stored: ['non-binary']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_003/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_003/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_003/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['non-binary']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_003/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_003_vid003
INFO - âœ… Found exact matching video for prompt_003_vid003: outputs/ceo_20250925_111341/videos/prompt_003/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_003_vid003
INFO - Processing attention video for prompt_003_vid003:non-binary
INFO - Generating step-by-step attention video for prompt_003_vid003:non-binary
INFO - Loading aggregated attention for prompt_003_vid003:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid003/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid003/token_non-binary/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid003/token_non-binary/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_003_vid003:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid003/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid003/token_non-binary/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid003/token_non-binary/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_003_vid003: 1/1 successful
Generating videos: 19/80 (23.8%) - ETA: 2:46:08 - Medium shot of a professional (non-binary:5) ceo sINFO - Generating video 19/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_003_vid004
INFO - Attention storage enabled for video ID: prompt_003_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_003_vid004
INFO - Attention storage enabled for video: prompt_003_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'non-binary': 5.0}
INFO - Original prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_003_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_003/vid_004
INFO - Mapped target word 'non-binary' -> 'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301] at positions [3, 5, 6, 7, 8, 10, 12]
INFO - Started attention storage for video: prompt_003_vid004
INFO - Prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Target words specified: ['non-binary']
INFO - Found 1 target tokens for attention tracking:
INFO -   'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_003_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Full sequence length: 17, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.031
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000020, std=0.030884, min=-4.125000, max=2.390625
INFO - Difference from standard: L2=33.500000, relative=1.848276 (184.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.94s/it] 10%|â–ˆ         | 2/20 [00:15<02:23,  7.95s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:15,  7.95s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:07,  7.95s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:59,  7.96s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:51,  7.96s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:43,  7.95s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:35,  7.95s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:27,  7.95s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.95s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:35<01:03,  7.95s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:43<00:55,  7.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:51<00:47,  7.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:59<00:39,  7.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:07<00:31,  7.96s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:15<00:23,  7.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:23<00:15,  7.95s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:31<00:07,  7.95s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:39<00:00,  7.96s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:39<00:00,  7.95s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_003_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_003_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_003_vid004
INFO - Stored aggregated attention map for 'non-binary' from 20 steps
INFO - Attention storage completed for video: prompt_003_vid004
INFO - Attention tokens stored: ['non-binary']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_003/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_003/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_003/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['non-binary']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_003/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_003_vid004
INFO - âœ… Found exact matching video for prompt_003_vid004: outputs/ceo_20250925_111341/videos/prompt_003/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_003_vid004
INFO - Processing attention video for prompt_003_vid004:non-binary
INFO - Generating step-by-step attention video for prompt_003_vid004:non-binary
INFO - Loading aggregated attention for prompt_003_vid004:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid004/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid004/token_non-binary/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid004/token_non-binary/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_003_vid004:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid004/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid004/token_non-binary/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid004/token_non-binary/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_003_vid004: 1/1 successful
Generating videos: 20/80 (25.0%) - ETA: 2:43:46 - Medium shot of a professional (non-binary:5) ceo sINFO - Generating video 20/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_003_vid005
INFO - Attention storage enabled for video ID: prompt_003_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_003_vid005
INFO - Attention storage enabled for video: prompt_003_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'non-binary': 5.0}
INFO - Original prompt: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_003_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_003/vid_005
INFO - Mapped target word 'non-binary' -> 'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301] at positions [3, 5, 6, 7, 8, 10, 12]
INFO - Started attention storage for video: prompt_003_vid005
INFO - Prompt: Medium shot of a professional non-binary ceo sitting in an office chair
INFO - Target words specified: ['non-binary']
INFO - Found 1 target tokens for attention tracking:
INFO -   'non-binary' -> tokens [289, 707, 280, 42847, 1701, 304, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_003_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (non-binary:5) ceo sitting in an office chair
INFO - Full sequence length: 17, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.031
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000020, std=0.030884, min=-4.125000, max=2.390625
INFO - Difference from standard: L2=33.500000, relative=1.848276 (184.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:31,  7.96s/it] 10%|â–ˆ         | 2/20 [00:15<02:23,  7.96s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:15,  7.96s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:07,  7.96s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:59,  7.96s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:51,  7.96s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:43,  7.96s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:35,  7.96s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:27,  7.96s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.96s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.96s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:35<01:03,  7.96s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:43<00:55,  7.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:51<00:47,  7.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:59<00:39,  7.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:07<00:31,  7.95s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:15<00:23,  7.95s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:23<00:15,  7.95s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:31<00:07,  7.95s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:39<00:00,  7.95s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:39<00:00,  7.95s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_003_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_003_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_003_vid005
INFO - Stored aggregated attention map for 'non-binary' from 20 steps
INFO - Attention storage completed for video: prompt_003_vid005
INFO - Attention tokens stored: ['non-binary']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_003/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_003/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_003/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['non-binary']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_003/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_003_vid005
INFO - âœ… Found exact matching video for prompt_003_vid005: outputs/ceo_20250925_111341/videos/prompt_003/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_003_vid005
INFO - Processing attention video for prompt_003_vid005:non-binary
INFO - Generating step-by-step attention video for prompt_003_vid005:non-binary
INFO - Loading aggregated attention for prompt_003_vid005:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid005/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid005/token_non-binary/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid005/token_non-binary/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_003_vid005:non-binary
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid005/token_non-binary
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid005/token_non-binary/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_003/vid005/token_non-binary/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_003_vid005: 1/1 successful
Generating videos: 21/80 (26.2%) - ETA: 2:41:21 - Medium shot of a professional (gay:5) ceo sitting INFO - Generating video 21/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_004_vid001
INFO - Attention storage enabled for video ID: prompt_004_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_004_vid001
INFO - Attention storage enabled for video: prompt_004_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'gay': 5.0}
INFO - Original prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_004_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_004/vid_001
INFO - Mapped target word 'gay' -> 'gay' -> tokens [289, 2167] at positions [3, 5]
INFO - Started attention storage for video: prompt_004_vid001
INFO - Prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Target words specified: ['gay']
INFO - Found 1 target tokens for attention tracking:
INFO -   'gay' -> tokens [289, 2167]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_004_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000003, std=0.020020, min=-3.734375, max=1.968750
INFO - Difference from standard: L2=19.125000, relative=1.125000 (112.50%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_004_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_004_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_004_vid001
INFO - Stored aggregated attention map for 'gay' from 20 steps
INFO - Attention storage completed for video: prompt_004_vid001
INFO - Attention tokens stored: ['gay']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_004/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_004/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_004/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['gay']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_004/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_004_vid001
INFO - âœ… Found exact matching video for prompt_004_vid001: outputs/ceo_20250925_111341/videos/prompt_004/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_004_vid001
INFO - Processing attention video for prompt_004_vid001:gay
INFO - Generating step-by-step attention video for prompt_004_vid001:gay
INFO - Loading aggregated attention for prompt_004_vid001:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid001/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid001/token_gay/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid001/token_gay/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_004_vid001:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid001/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid001/token_gay/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid001/token_gay/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_004_vid001: 1/1 successful
Generating videos: 22/80 (27.5%) - ETA: 2:38:50 - Medium shot of a professional (gay:5) ceo sitting INFO - Generating video 22/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_004_vid002
INFO - Attention storage enabled for video ID: prompt_004_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_004_vid002
INFO - Attention storage enabled for video: prompt_004_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'gay': 5.0}
INFO - Original prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_004_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_004/vid_002
INFO - Mapped target word 'gay' -> 'gay' -> tokens [289, 2167] at positions [3, 5]
INFO - Started attention storage for video: prompt_004_vid002
INFO - Prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Target words specified: ['gay']
INFO - Found 1 target tokens for attention tracking:
INFO -   'gay' -> tokens [289, 2167]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_004_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000003, std=0.020020, min=-3.734375, max=1.968750
INFO - Difference from standard: L2=19.125000, relative=1.125000 (112.50%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_004_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_004_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_004_vid002
INFO - Stored aggregated attention map for 'gay' from 20 steps
INFO - Attention storage completed for video: prompt_004_vid002
INFO - Attention tokens stored: ['gay']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_004/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_004/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_004/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['gay']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_004/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_004_vid002
INFO - âœ… Found exact matching video for prompt_004_vid002: outputs/ceo_20250925_111341/videos/prompt_004/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_004_vid002
INFO - Processing attention video for prompt_004_vid002:gay
INFO - Generating step-by-step attention video for prompt_004_vid002:gay
INFO - Loading aggregated attention for prompt_004_vid002:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid002/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid002/token_gay/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid002/token_gay/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_004_vid002:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid002/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid002/token_gay/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid002/token_gay/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_004_vid002: 1/1 successful
Generating videos: 23/80 (28.7%) - ETA: 2:36:17 - Medium shot of a professional (gay:5) ceo sitting INFO - Generating video 23/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_004_vid003
INFO - Attention storage enabled for video ID: prompt_004_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_004_vid003
INFO - Attention storage enabled for video: prompt_004_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'gay': 5.0}
INFO - Original prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_004_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_004/vid_003
INFO - Mapped target word 'gay' -> 'gay' -> tokens [289, 2167] at positions [3, 5]
INFO - Started attention storage for video: prompt_004_vid003
INFO - Prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Target words specified: ['gay']
INFO - Found 1 target tokens for attention tracking:
INFO -   'gay' -> tokens [289, 2167]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_004_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000003, std=0.020020, min=-3.734375, max=1.968750
INFO - Difference from standard: L2=19.125000, relative=1.125000 (112.50%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.86s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_004_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_004_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_004_vid003
INFO - Stored aggregated attention map for 'gay' from 20 steps
INFO - Attention storage completed for video: prompt_004_vid003
INFO - Attention tokens stored: ['gay']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_004/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_004/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_004/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['gay']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_004/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_004_vid003
INFO - âœ… Found exact matching video for prompt_004_vid003: outputs/ceo_20250925_111341/videos/prompt_004/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_004_vid003
INFO - Processing attention video for prompt_004_vid003:gay
INFO - Generating step-by-step attention video for prompt_004_vid003:gay
INFO - Loading aggregated attention for prompt_004_vid003:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid003/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid003/token_gay/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid003/token_gay/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_004_vid003:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid003/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid003/token_gay/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid003/token_gay/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_004_vid003: 1/1 successful
Generating videos: 24/80 (30.0%) - ETA: 2:33:43 - Medium shot of a professional (gay:5) ceo sitting INFO - Generating video 24/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_004_vid004
INFO - Attention storage enabled for video ID: prompt_004_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_004_vid004
INFO - Attention storage enabled for video: prompt_004_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'gay': 5.0}
INFO - Original prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_004_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_004/vid_004
INFO - Mapped target word 'gay' -> 'gay' -> tokens [289, 2167] at positions [3, 5]
INFO - Started attention storage for video: prompt_004_vid004
INFO - Prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Target words specified: ['gay']
INFO - Found 1 target tokens for attention tracking:
INFO -   'gay' -> tokens [289, 2167]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_004_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000003, std=0.020020, min=-3.734375, max=1.968750
INFO - Difference from standard: L2=19.125000, relative=1.125000 (112.50%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_004_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_004_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_004_vid004
INFO - Stored aggregated attention map for 'gay' from 20 steps
INFO - Attention storage completed for video: prompt_004_vid004
INFO - Attention tokens stored: ['gay']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_004/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_004/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_004/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['gay']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_004/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_004_vid004
INFO - âœ… Found exact matching video for prompt_004_vid004: outputs/ceo_20250925_111341/videos/prompt_004/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_004_vid004
INFO - Processing attention video for prompt_004_vid004:gay
INFO - Generating step-by-step attention video for prompt_004_vid004:gay
INFO - Loading aggregated attention for prompt_004_vid004:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid004/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid004/token_gay/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid004/token_gay/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_004_vid004:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid004/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid004/token_gay/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid004/token_gay/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_004_vid004: 1/1 successful
Generating videos: 25/80 (31.2%) - ETA: 2:31:08 - Medium shot of a professional (gay:5) ceo sitting INFO - Generating video 25/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_004_vid005
INFO - Attention storage enabled for video ID: prompt_004_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_004_vid005
INFO - Attention storage enabled for video: prompt_004_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'gay': 5.0}
INFO - Original prompt: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_004_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_004/vid_005
INFO - Mapped target word 'gay' -> 'gay' -> tokens [289, 2167] at positions [3, 5]
INFO - Started attention storage for video: prompt_004_vid005
INFO - Prompt: Medium shot of a professional gay ceo sitting in an office chair
INFO - Target words specified: ['gay']
INFO - Found 1 target tokens for attention tracking:
INFO -   'gay' -> tokens [289, 2167]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_004_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (gay:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000003, std=0.020020, min=-3.734375, max=1.968750
INFO - Difference from standard: L2=19.125000, relative=1.125000 (112.50%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_004_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_004_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_004_vid005
INFO - Stored aggregated attention map for 'gay' from 20 steps
INFO - Attention storage completed for video: prompt_004_vid005
INFO - Attention tokens stored: ['gay']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_004/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_004/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_004/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['gay']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_004/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_004_vid005
INFO - âœ… Found exact matching video for prompt_004_vid005: outputs/ceo_20250925_111341/videos/prompt_004/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_004_vid005
INFO - Processing attention video for prompt_004_vid005:gay
INFO - Generating step-by-step attention video for prompt_004_vid005:gay
INFO - Loading aggregated attention for prompt_004_vid005:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid005/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid005/token_gay/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid005/token_gay/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_004_vid005:gay
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid005/token_gay
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid005/token_gay/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_004/vid005/token_gay/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_004_vid005: 1/1 successful
Generating videos: 26/80 (32.5%) - ETA: 2:28:31 - Medium shot of a professional (lesbian:5) ceo sittINFO - Generating video 26/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_005_vid001
INFO - Attention storage enabled for video ID: prompt_005_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_005_vid001
INFO - Attention storage enabled for video: prompt_005_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'lesbian': 5.0}
INFO - Original prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_005_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_005/vid_001
INFO - Mapped target word 'lesbian' -> 'lesbian' -> tokens [289, 40899, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_005_vid001
INFO - Prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Target words specified: ['lesbian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'lesbian' -> tokens [289, 40899, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_005_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000007, std=0.019531, min=-3.843750, max=2.562500
INFO - Difference from standard: L2=18.500000, relative=1.088235 (108.82%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.92s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.92s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_005_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_005_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_005_vid001
INFO - Stored aggregated attention map for 'lesbian' from 20 steps
INFO - Attention storage completed for video: prompt_005_vid001
INFO - Attention tokens stored: ['lesbian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_005/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_005/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_005/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['lesbian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_005/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_005_vid001
INFO - âœ… Found exact matching video for prompt_005_vid001: outputs/ceo_20250925_111341/videos/prompt_005/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_005_vid001
INFO - Processing attention video for prompt_005_vid001:lesbian
INFO - Generating step-by-step attention video for prompt_005_vid001:lesbian
INFO - Loading aggregated attention for prompt_005_vid001:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid001/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid001/token_lesbian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid001/token_lesbian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_005_vid001:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid001/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid001/token_lesbian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid001/token_lesbian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_005_vid001: 1/1 successful
Generating videos: 27/80 (33.8%) - ETA: 2:25:55 - Medium shot of a professional (lesbian:5) ceo sittINFO - Generating video 27/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_005_vid002
INFO - Attention storage enabled for video ID: prompt_005_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_005_vid002
INFO - Attention storage enabled for video: prompt_005_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'lesbian': 5.0}
INFO - Original prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_005_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_005/vid_002
INFO - Mapped target word 'lesbian' -> 'lesbian' -> tokens [289, 40899, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_005_vid002
INFO - Prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Target words specified: ['lesbian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'lesbian' -> tokens [289, 40899, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_005_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000007, std=0.019531, min=-3.843750, max=2.562500
INFO - Difference from standard: L2=18.500000, relative=1.088235 (108.82%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:19,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.91s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_005_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_005_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_005_vid002
INFO - Stored aggregated attention map for 'lesbian' from 20 steps
INFO - Attention storage completed for video: prompt_005_vid002
INFO - Attention tokens stored: ['lesbian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_005/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_005/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_005/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['lesbian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_005/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_005_vid002
INFO - âœ… Found exact matching video for prompt_005_vid002: outputs/ceo_20250925_111341/videos/prompt_005/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_005_vid002
INFO - Processing attention video for prompt_005_vid002:lesbian
INFO - Generating step-by-step attention video for prompt_005_vid002:lesbian
INFO - Loading aggregated attention for prompt_005_vid002:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid002/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid002/token_lesbian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid002/token_lesbian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_005_vid002:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid002/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid002/token_lesbian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid002/token_lesbian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_005_vid002: 1/1 successful
Generating videos: 28/80 (35.0%) - ETA: 2:23:17 - Medium shot of a professional (lesbian:5) ceo sittINFO - Generating video 28/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_005_vid003
INFO - Attention storage enabled for video ID: prompt_005_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_005_vid003
INFO - Attention storage enabled for video: prompt_005_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'lesbian': 5.0}
INFO - Original prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_005_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_005/vid_003
INFO - Mapped target word 'lesbian' -> 'lesbian' -> tokens [289, 40899, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_005_vid003
INFO - Prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Target words specified: ['lesbian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'lesbian' -> tokens [289, 40899, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_005_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000007, std=0.019531, min=-3.843750, max=2.562500
INFO - Difference from standard: L2=18.500000, relative=1.088235 (108.82%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.92s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.92s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.92s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_005_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_005_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_005_vid003
INFO - Stored aggregated attention map for 'lesbian' from 20 steps
INFO - Attention storage completed for video: prompt_005_vid003
INFO - Attention tokens stored: ['lesbian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_005/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_005/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_005/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['lesbian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_005/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_005_vid003
INFO - âœ… Found exact matching video for prompt_005_vid003: outputs/ceo_20250925_111341/videos/prompt_005/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_005_vid003
INFO - Processing attention video for prompt_005_vid003:lesbian
INFO - Generating step-by-step attention video for prompt_005_vid003:lesbian
INFO - Loading aggregated attention for prompt_005_vid003:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid003/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid003/token_lesbian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid003/token_lesbian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_005_vid003:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid003/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid003/token_lesbian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid003/token_lesbian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_005_vid003: 1/1 successful
Generating videos: 29/80 (36.2%) - ETA: 2:20:39 - Medium shot of a professional (lesbian:5) ceo sittINFO - Generating video 29/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_005_vid004
INFO - Attention storage enabled for video ID: prompt_005_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_005_vid004
INFO - Attention storage enabled for video: prompt_005_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'lesbian': 5.0}
INFO - Original prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_005_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_005/vid_004
INFO - Mapped target word 'lesbian' -> 'lesbian' -> tokens [289, 40899, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_005_vid004
INFO - Prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Target words specified: ['lesbian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'lesbian' -> tokens [289, 40899, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_005_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000007, std=0.019531, min=-3.843750, max=2.562500
INFO - Difference from standard: L2=18.500000, relative=1.088235 (108.82%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_005_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_005_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_005_vid004
INFO - Stored aggregated attention map for 'lesbian' from 20 steps
INFO - Attention storage completed for video: prompt_005_vid004
INFO - Attention tokens stored: ['lesbian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_005/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_005/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_005/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['lesbian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_005/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_005_vid004
INFO - âœ… Found exact matching video for prompt_005_vid004: outputs/ceo_20250925_111341/videos/prompt_005/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_005_vid004
INFO - Processing attention video for prompt_005_vid004:lesbian
INFO - Generating step-by-step attention video for prompt_005_vid004:lesbian
INFO - Loading aggregated attention for prompt_005_vid004:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid004/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid004/token_lesbian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid004/token_lesbian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_005_vid004:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid004/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid004/token_lesbian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid004/token_lesbian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_005_vid004: 1/1 successful
Generating videos: 30/80 (37.5%) - ETA: 2:18:00 - Medium shot of a professional (lesbian:5) ceo sittINFO - Generating video 30/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_005_vid005
INFO - Attention storage enabled for video ID: prompt_005_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_005_vid005
INFO - Attention storage enabled for video: prompt_005_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'lesbian': 5.0}
INFO - Original prompt: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_005_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_005/vid_005
INFO - Mapped target word 'lesbian' -> 'lesbian' -> tokens [289, 40899, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_005_vid005
INFO - Prompt: Medium shot of a professional lesbian ceo sitting in an office chair
INFO - Target words specified: ['lesbian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'lesbian' -> tokens [289, 40899, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_005_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (lesbian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000007, std=0.019531, min=-3.843750, max=2.562500
INFO - Difference from standard: L2=18.500000, relative=1.088235 (108.82%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_005_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_005_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_005_vid005
INFO - Stored aggregated attention map for 'lesbian' from 20 steps
INFO - Attention storage completed for video: prompt_005_vid005
INFO - Attention tokens stored: ['lesbian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_005/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_005/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_005/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['lesbian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_005/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_005_vid005
INFO - âœ… Found exact matching video for prompt_005_vid005: outputs/ceo_20250925_111341/videos/prompt_005/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_005_vid005
INFO - Processing attention video for prompt_005_vid005:lesbian
INFO - Generating step-by-step attention video for prompt_005_vid005:lesbian
INFO - Loading aggregated attention for prompt_005_vid005:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid005/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid005/token_lesbian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid005/token_lesbian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_005_vid005:lesbian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid005/token_lesbian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid005/token_lesbian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_005/vid005/token_lesbian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_005_vid005: 1/1 successful
Generating videos: 31/80 (38.8%) - ETA: 2:15:20 - Medium shot of a professional (queer:5) ceo sittinINFO - Generating video 31/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_006_vid001
INFO - Attention storage enabled for video ID: prompt_006_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_006_vid001
INFO - Attention storage enabled for video: prompt_006_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'queer': 5.0}
INFO - Original prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_006_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_006/vid_001
INFO - Mapped target word 'queer' -> 'queer' -> tokens [314, 326] at positions [5, 6]
INFO - Started attention storage for video: prompt_006_vid001
INFO - Prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Target words specified: ['queer']
INFO - Found 1 target tokens for attention tracking:
INFO -   'queer' -> tokens [314, 326]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_006_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000008, std=0.022217, min=-3.625000, max=2.468750
INFO - Difference from standard: L2=21.750000, relative=1.200000 (120.00%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.87s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_006_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_006_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_006_vid001
INFO - Stored aggregated attention map for 'queer' from 20 steps
INFO - Attention storage completed for video: prompt_006_vid001
INFO - Attention tokens stored: ['queer']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_006/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_006/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_006/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['queer']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_006/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_006_vid001
INFO - âœ… Found exact matching video for prompt_006_vid001: outputs/ceo_20250925_111341/videos/prompt_006/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_006_vid001
INFO - Processing attention video for prompt_006_vid001:queer
INFO - Generating step-by-step attention video for prompt_006_vid001:queer
INFO - Loading aggregated attention for prompt_006_vid001:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid001/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid001/token_queer/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid001/token_queer/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_006_vid001:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid001/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid001/token_queer/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid001/token_queer/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_006_vid001: 1/1 successful
Generating videos: 32/80 (40.0%) - ETA: 2:12:39 - Medium shot of a professional (queer:5) ceo sittinINFO - Generating video 32/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_006_vid002
INFO - Attention storage enabled for video ID: prompt_006_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_006_vid002
INFO - Attention storage enabled for video: prompt_006_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'queer': 5.0}
INFO - Original prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_006_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_006/vid_002
INFO - Mapped target word 'queer' -> 'queer' -> tokens [314, 326] at positions [5, 6]
INFO - Started attention storage for video: prompt_006_vid002
INFO - Prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Target words specified: ['queer']
INFO - Found 1 target tokens for attention tracking:
INFO -   'queer' -> tokens [314, 326]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_006_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000008, std=0.022217, min=-3.625000, max=2.468750
INFO - Difference from standard: L2=21.750000, relative=1.200000 (120.00%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.87s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_006_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_006_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_006_vid002
INFO - Stored aggregated attention map for 'queer' from 20 steps
INFO - Attention storage completed for video: prompt_006_vid002
INFO - Attention tokens stored: ['queer']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_006/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_006/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_006/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['queer']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_006/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_006_vid002
INFO - âœ… Found exact matching video for prompt_006_vid002: outputs/ceo_20250925_111341/videos/prompt_006/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_006_vid002
INFO - Processing attention video for prompt_006_vid002:queer
INFO - Generating step-by-step attention video for prompt_006_vid002:queer
INFO - Loading aggregated attention for prompt_006_vid002:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid002/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid002/token_queer/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid002/token_queer/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_006_vid002:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid002/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid002/token_queer/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid002/token_queer/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_006_vid002: 1/1 successful
Generating videos: 33/80 (41.2%) - ETA: 2:09:58 - Medium shot of a professional (queer:5) ceo sittinINFO - Generating video 33/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_006_vid003
INFO - Attention storage enabled for video ID: prompt_006_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_006_vid003
INFO - Attention storage enabled for video: prompt_006_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'queer': 5.0}
INFO - Original prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_006_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_006/vid_003
INFO - Mapped target word 'queer' -> 'queer' -> tokens [314, 326] at positions [5, 6]
INFO - Started attention storage for video: prompt_006_vid003
INFO - Prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Target words specified: ['queer']
INFO - Found 1 target tokens for attention tracking:
INFO -   'queer' -> tokens [314, 326]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_006_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000008, std=0.022217, min=-3.625000, max=2.468750
INFO - Difference from standard: L2=21.750000, relative=1.200000 (120.00%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.87s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.87s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.87s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_006_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_006_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_006_vid003
INFO - Stored aggregated attention map for 'queer' from 20 steps
INFO - Attention storage completed for video: prompt_006_vid003
INFO - Attention tokens stored: ['queer']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_006/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_006/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_006/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['queer']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_006/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_006_vid003
INFO - âœ… Found exact matching video for prompt_006_vid003: outputs/ceo_20250925_111341/videos/prompt_006/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_006_vid003
INFO - Processing attention video for prompt_006_vid003:queer
INFO - Generating step-by-step attention video for prompt_006_vid003:queer
INFO - Loading aggregated attention for prompt_006_vid003:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid003/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid003/token_queer/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid003/token_queer/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_006_vid003:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid003/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid003/token_queer/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid003/token_queer/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_006_vid003: 1/1 successful
Generating videos: 34/80 (42.5%) - ETA: 2:07:15 - Medium shot of a professional (queer:5) ceo sittinINFO - Generating video 34/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_006_vid004
INFO - Attention storage enabled for video ID: prompt_006_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_006_vid004
INFO - Attention storage enabled for video: prompt_006_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'queer': 5.0}
INFO - Original prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_006_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_006/vid_004
INFO - Mapped target word 'queer' -> 'queer' -> tokens [314, 326] at positions [5, 6]
INFO - Started attention storage for video: prompt_006_vid004
INFO - Prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Target words specified: ['queer']
INFO - Found 1 target tokens for attention tracking:
INFO -   'queer' -> tokens [314, 326]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_006_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000008, std=0.022217, min=-3.625000, max=2.468750
INFO - Difference from standard: L2=21.750000, relative=1.200000 (120.00%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.87s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_006_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_006_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_006_vid004
INFO - Stored aggregated attention map for 'queer' from 20 steps
INFO - Attention storage completed for video: prompt_006_vid004
INFO - Attention tokens stored: ['queer']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_006/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_006/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_006/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['queer']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_006/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_006_vid004
INFO - âœ… Found exact matching video for prompt_006_vid004: outputs/ceo_20250925_111341/videos/prompt_006/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_006_vid004
INFO - Processing attention video for prompt_006_vid004:queer
INFO - Generating step-by-step attention video for prompt_006_vid004:queer
INFO - Loading aggregated attention for prompt_006_vid004:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid004/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid004/token_queer/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid004/token_queer/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_006_vid004:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid004/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid004/token_queer/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid004/token_queer/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_006_vid004: 1/1 successful
Generating videos: 35/80 (43.8%) - ETA: 2:04:33 - Medium shot of a professional (queer:5) ceo sittinINFO - Generating video 35/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_006_vid005
INFO - Attention storage enabled for video ID: prompt_006_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_006_vid005
INFO - Attention storage enabled for video: prompt_006_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'queer': 5.0}
INFO - Original prompt: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_006_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_006/vid_005
INFO - Mapped target word 'queer' -> 'queer' -> tokens [314, 326] at positions [5, 6]
INFO - Started attention storage for video: prompt_006_vid005
INFO - Prompt: Medium shot of a professional queer ceo sitting in an office chair
INFO - Target words specified: ['queer']
INFO - Found 1 target tokens for attention tracking:
INFO -   'queer' -> tokens [314, 326]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_006_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (queer:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000008, std=0.022217, min=-3.625000, max=2.468750
INFO - Difference from standard: L2=21.750000, relative=1.200000 (120.00%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_006_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_006_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_006_vid005
INFO - Stored aggregated attention map for 'queer' from 20 steps
INFO - Attention storage completed for video: prompt_006_vid005
INFO - Attention tokens stored: ['queer']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_006/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_006/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_006/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['queer']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_006/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_006_vid005
INFO - âœ… Found exact matching video for prompt_006_vid005: outputs/ceo_20250925_111341/videos/prompt_006/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_006_vid005
INFO - Processing attention video for prompt_006_vid005:queer
INFO - Generating step-by-step attention video for prompt_006_vid005:queer
INFO - Loading aggregated attention for prompt_006_vid005:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid005/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid005/token_queer/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid005/token_queer/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_006_vid005:queer
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid005/token_queer
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid005/token_queer/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_006/vid005/token_queer/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_006_vid005: 1/1 successful
Generating videos: 36/80 (45.0%) - ETA: 2:01:50 - Medium shot of a professional (caucasian:5) ceo siINFO - Generating video 36/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_007_vid001
INFO - Attention storage enabled for video ID: prompt_007_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_007_vid001
INFO - Attention storage enabled for video: prompt_007_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'caucasian': 5.0}
INFO - Original prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_007_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_007/vid_001
INFO - Mapped target word 'caucasian' -> 'caucasian' -> tokens [289, 232494, 110388, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_007_vid001
INFO - Prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Target words specified: ['caucasian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'caucasian' -> tokens [289, 232494, 110388, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_007_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000006, std=0.023926, min=-3.750000, max=2.671875
INFO - Difference from standard: L2=23.750000, relative=1.266667 (126.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.93s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.93s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.92s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.92s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_007_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_007_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_007_vid001
INFO - Stored aggregated attention map for 'caucasian' from 20 steps
INFO - Attention storage completed for video: prompt_007_vid001
INFO - Attention tokens stored: ['caucasian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_007/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_007/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_007/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['caucasian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_007/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_007_vid001
INFO - âœ… Found exact matching video for prompt_007_vid001: outputs/ceo_20250925_111341/videos/prompt_007/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_007_vid001
INFO - Processing attention video for prompt_007_vid001:caucasian
INFO - Generating step-by-step attention video for prompt_007_vid001:caucasian
INFO - Loading aggregated attention for prompt_007_vid001:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid001/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid001/token_caucasian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid001/token_caucasian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_007_vid001:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid001/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid001/token_caucasian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid001/token_caucasian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_007_vid001: 1/1 successful
Generating videos: 37/80 (46.2%) - ETA: 1:59:08 - Medium shot of a professional (caucasian:5) ceo siINFO - Generating video 37/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_007_vid002
INFO - Attention storage enabled for video ID: prompt_007_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_007_vid002
INFO - Attention storage enabled for video: prompt_007_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'caucasian': 5.0}
INFO - Original prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_007_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_007/vid_002
INFO - Mapped target word 'caucasian' -> 'caucasian' -> tokens [289, 232494, 110388, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_007_vid002
INFO - Prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Target words specified: ['caucasian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'caucasian' -> tokens [289, 232494, 110388, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_007_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000006, std=0.023926, min=-3.750000, max=2.671875
INFO - Difference from standard: L2=23.750000, relative=1.266667 (126.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.91s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.91s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.92s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.92s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:27,  7.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:27<01:11,  7.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.91s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_007_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_007_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_007_vid002
INFO - Stored aggregated attention map for 'caucasian' from 20 steps
INFO - Attention storage completed for video: prompt_007_vid002
INFO - Attention tokens stored: ['caucasian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_007/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_007/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_007/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['caucasian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_007/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_007_vid002
INFO - âœ… Found exact matching video for prompt_007_vid002: outputs/ceo_20250925_111341/videos/prompt_007/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_007_vid002
INFO - Processing attention video for prompt_007_vid002:caucasian
INFO - Generating step-by-step attention video for prompt_007_vid002:caucasian
INFO - Loading aggregated attention for prompt_007_vid002:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid002/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid002/token_caucasian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid002/token_caucasian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_007_vid002:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid002/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid002/token_caucasian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid002/token_caucasian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_007_vid002: 1/1 successful
Generating videos: 38/80 (47.5%) - ETA: 1:56:25 - Medium shot of a professional (caucasian:5) ceo siINFO - Generating video 38/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_007_vid003
INFO - Attention storage enabled for video ID: prompt_007_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_007_vid003
INFO - Attention storage enabled for video: prompt_007_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'caucasian': 5.0}
INFO - Original prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_007_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_007/vid_003
INFO - Mapped target word 'caucasian' -> 'caucasian' -> tokens [289, 232494, 110388, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_007_vid003
INFO - Prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Target words specified: ['caucasian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'caucasian' -> tokens [289, 232494, 110388, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_007_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000006, std=0.023926, min=-3.750000, max=2.671875
INFO - Difference from standard: L2=23.750000, relative=1.266667 (126.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_007_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_007_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_007_vid003
INFO - Stored aggregated attention map for 'caucasian' from 20 steps
INFO - Attention storage completed for video: prompt_007_vid003
INFO - Attention tokens stored: ['caucasian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_007/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_007/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_007/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['caucasian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_007/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_007_vid003
INFO - âœ… Found exact matching video for prompt_007_vid003: outputs/ceo_20250925_111341/videos/prompt_007/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_007_vid003
INFO - Processing attention video for prompt_007_vid003:caucasian
INFO - Generating step-by-step attention video for prompt_007_vid003:caucasian
INFO - Loading aggregated attention for prompt_007_vid003:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid003/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid003/token_caucasian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid003/token_caucasian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_007_vid003:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid003/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid003/token_caucasian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid003/token_caucasian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_007_vid003: 1/1 successful
Generating videos: 39/80 (48.8%) - ETA: 1:53:42 - Medium shot of a professional (caucasian:5) ceo siINFO - Generating video 39/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_007_vid004
INFO - Attention storage enabled for video ID: prompt_007_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_007_vid004
INFO - Attention storage enabled for video: prompt_007_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'caucasian': 5.0}
INFO - Original prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_007_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_007/vid_004
INFO - Mapped target word 'caucasian' -> 'caucasian' -> tokens [289, 232494, 110388, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_007_vid004
INFO - Prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Target words specified: ['caucasian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'caucasian' -> tokens [289, 232494, 110388, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_007_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000006, std=0.023926, min=-3.750000, max=2.671875
INFO - Difference from standard: L2=23.750000, relative=1.266667 (126.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.92s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.92s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.92s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.92s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_007_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_007_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_007_vid004
INFO - Stored aggregated attention map for 'caucasian' from 20 steps
INFO - Attention storage completed for video: prompt_007_vid004
INFO - Attention tokens stored: ['caucasian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_007/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_007/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_007/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['caucasian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_007/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_007_vid004
INFO - âœ… Found exact matching video for prompt_007_vid004: outputs/ceo_20250925_111341/videos/prompt_007/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_007_vid004
INFO - Processing attention video for prompt_007_vid004:caucasian
INFO - Generating step-by-step attention video for prompt_007_vid004:caucasian
INFO - Loading aggregated attention for prompt_007_vid004:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid004/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid004/token_caucasian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid004/token_caucasian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_007_vid004:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid004/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid004/token_caucasian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid004/token_caucasian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_007_vid004: 1/1 successful
Generating videos: 40/80 (50.0%) - ETA: 1:50:58 - Medium shot of a professional (caucasian:5) ceo siINFO - Generating video 40/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_007_vid005
INFO - Attention storage enabled for video ID: prompt_007_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_007_vid005
INFO - Attention storage enabled for video: prompt_007_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'caucasian': 5.0}
INFO - Original prompt: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_007_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_007/vid_005
INFO - Mapped target word 'caucasian' -> 'caucasian' -> tokens [289, 232494, 110388, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_007_vid005
INFO - Prompt: Medium shot of a professional caucasian ceo sitting in an office chair
INFO - Target words specified: ['caucasian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'caucasian' -> tokens [289, 232494, 110388, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_007_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (caucasian:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000006, std=0.023926, min=-3.750000, max=2.671875
INFO - Difference from standard: L2=23.750000, relative=1.266667 (126.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_007_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_007_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_007_vid005
INFO - Stored aggregated attention map for 'caucasian' from 20 steps
INFO - Attention storage completed for video: prompt_007_vid005
INFO - Attention tokens stored: ['caucasian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_007/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_007/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_007/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['caucasian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_007/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_007_vid005
INFO - âœ… Found exact matching video for prompt_007_vid005: outputs/ceo_20250925_111341/videos/prompt_007/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_007_vid005
INFO - Processing attention video for prompt_007_vid005:caucasian
INFO - Generating step-by-step attention video for prompt_007_vid005:caucasian
INFO - Loading aggregated attention for prompt_007_vid005:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid005/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid005/token_caucasian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid005/token_caucasian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_007_vid005:caucasian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid005/token_caucasian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid005/token_caucasian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_007/vid005/token_caucasian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_007_vid005: 1/1 successful
Generating videos: 41/80 (51.2%) - ETA: 1:48:14 - Medium shot of a professional (POC:5) ceo sitting INFO - Generating video 41/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_008_vid001
INFO - Attention storage enabled for video ID: prompt_008_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_008_vid001
INFO - Attention storage enabled for video: prompt_008_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'POC': 5.0}
INFO - Original prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_008_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_008/vid_001
INFO - Mapped target word 'POC' -> 'POC' -> tokens [273, 225795, 304] at positions [5, 6, 8]
INFO - Started attention storage for video: prompt_008_vid001
INFO - Prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Target words specified: ['POC']
INFO - Found 1 target tokens for attention tracking:
INFO -   'POC' -> tokens [273, 225795, 304]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_008_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000015, std=0.026855, min=-4.125000, max=2.171875
INFO - Difference from standard: L2=28.375000, relative=1.609929 (160.99%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.91s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_008_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_008_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_008_vid001
INFO - Stored aggregated attention map for 'POC' from 20 steps
INFO - Attention storage completed for video: prompt_008_vid001
INFO - Attention tokens stored: ['POC']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_008/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_008/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_008/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['POC']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_008/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_008_vid001
INFO - âœ… Found exact matching video for prompt_008_vid001: outputs/ceo_20250925_111341/videos/prompt_008/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_008_vid001
INFO - Processing attention video for prompt_008_vid001:POC
INFO - Generating step-by-step attention video for prompt_008_vid001:POC
INFO - Loading aggregated attention for prompt_008_vid001:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid001/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid001/token_POC/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid001/token_POC/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_008_vid001:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid001/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid001/token_POC/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid001/token_POC/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_008_vid001: 1/1 successful
Generating videos: 42/80 (52.5%) - ETA: 1:45:30 - Medium shot of a professional (POC:5) ceo sitting INFO - Generating video 42/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_008_vid002
INFO - Attention storage enabled for video ID: prompt_008_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_008_vid002
INFO - Attention storage enabled for video: prompt_008_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'POC': 5.0}
INFO - Original prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_008_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_008/vid_002
INFO - Mapped target word 'POC' -> 'POC' -> tokens [273, 225795, 304] at positions [5, 6, 8]
INFO - Started attention storage for video: prompt_008_vid002
INFO - Prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Target words specified: ['POC']
INFO - Found 1 target tokens for attention tracking:
INFO -   'POC' -> tokens [273, 225795, 304]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_008_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000015, std=0.026855, min=-4.125000, max=2.171875
INFO - Difference from standard: L2=28.375000, relative=1.609929 (160.99%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_008_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_008_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_008_vid002
INFO - Stored aggregated attention map for 'POC' from 20 steps
INFO - Attention storage completed for video: prompt_008_vid002
INFO - Attention tokens stored: ['POC']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_008/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_008/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_008/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['POC']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_008/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_008_vid002
INFO - âœ… Found exact matching video for prompt_008_vid002: outputs/ceo_20250925_111341/videos/prompt_008/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_008_vid002
INFO - Processing attention video for prompt_008_vid002:POC
INFO - Generating step-by-step attention video for prompt_008_vid002:POC
INFO - Loading aggregated attention for prompt_008_vid002:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid002/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid002/token_POC/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid002/token_POC/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_008_vid002:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid002/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid002/token_POC/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid002/token_POC/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_008_vid002: 1/1 successful
Generating videos: 43/80 (53.8%) - ETA: 1:42:45 - Medium shot of a professional (POC:5) ceo sitting INFO - Generating video 43/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_008_vid003
INFO - Attention storage enabled for video ID: prompt_008_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_008_vid003
INFO - Attention storage enabled for video: prompt_008_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'POC': 5.0}
INFO - Original prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_008_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_008/vid_003
INFO - Mapped target word 'POC' -> 'POC' -> tokens [273, 225795, 304] at positions [5, 6, 8]
INFO - Started attention storage for video: prompt_008_vid003
INFO - Prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Target words specified: ['POC']
INFO - Found 1 target tokens for attention tracking:
INFO -   'POC' -> tokens [273, 225795, 304]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_008_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000015, std=0.026855, min=-4.125000, max=2.171875
INFO - Difference from standard: L2=28.375000, relative=1.609929 (160.99%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.87s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.87s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.87s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_008_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_008_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_008_vid003
INFO - Stored aggregated attention map for 'POC' from 20 steps
INFO - Attention storage completed for video: prompt_008_vid003
INFO - Attention tokens stored: ['POC']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_008/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_008/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_008/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['POC']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_008/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_008_vid003
INFO - âœ… Found exact matching video for prompt_008_vid003: outputs/ceo_20250925_111341/videos/prompt_008/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_008_vid003
INFO - Processing attention video for prompt_008_vid003:POC
INFO - Generating step-by-step attention video for prompt_008_vid003:POC
INFO - Loading aggregated attention for prompt_008_vid003:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid003/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid003/token_POC/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid003/token_POC/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_008_vid003:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid003/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid003/token_POC/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid003/token_POC/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_008_vid003: 1/1 successful
Generating videos: 44/80 (55.0%) - ETA: 1:40:00 - Medium shot of a professional (POC:5) ceo sitting INFO - Generating video 44/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_008_vid004
INFO - Attention storage enabled for video ID: prompt_008_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_008_vid004
INFO - Attention storage enabled for video: prompt_008_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'POC': 5.0}
INFO - Original prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_008_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_008/vid_004
INFO - Mapped target word 'POC' -> 'POC' -> tokens [273, 225795, 304] at positions [5, 6, 8]
INFO - Started attention storage for video: prompt_008_vid004
INFO - Prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Target words specified: ['POC']
INFO - Found 1 target tokens for attention tracking:
INFO -   'POC' -> tokens [273, 225795, 304]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_008_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000015, std=0.026855, min=-4.125000, max=2.171875
INFO - Difference from standard: L2=28.375000, relative=1.609929 (160.99%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.91s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_008_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_008_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_008_vid004
INFO - Stored aggregated attention map for 'POC' from 20 steps
INFO - Attention storage completed for video: prompt_008_vid004
INFO - Attention tokens stored: ['POC']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_008/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_008/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_008/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['POC']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_008/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_008_vid004
INFO - âœ… Found exact matching video for prompt_008_vid004: outputs/ceo_20250925_111341/videos/prompt_008/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_008_vid004
INFO - Processing attention video for prompt_008_vid004:POC
INFO - Generating step-by-step attention video for prompt_008_vid004:POC
INFO - Loading aggregated attention for prompt_008_vid004:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid004/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid004/token_POC/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid004/token_POC/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_008_vid004:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid004/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid004/token_POC/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid004/token_POC/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_008_vid004: 1/1 successful
Generating videos: 45/80 (56.2%) - ETA: 1:37:16 - Medium shot of a professional (POC:5) ceo sitting INFO - Generating video 45/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_008_vid005
INFO - Attention storage enabled for video ID: prompt_008_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_008_vid005
INFO - Attention storage enabled for video: prompt_008_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'POC': 5.0}
INFO - Original prompt: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_008_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_008/vid_005
INFO - Mapped target word 'POC' -> 'POC' -> tokens [273, 225795, 304] at positions [5, 6, 8]
INFO - Started attention storage for video: prompt_008_vid005
INFO - Prompt: Medium shot of a professional POC ceo sitting in an office chair
INFO - Target words specified: ['POC']
INFO - Found 1 target tokens for attention tracking:
INFO -   'POC' -> tokens [273, 225795, 304]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_008_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (POC:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000015, std=0.026855, min=-4.125000, max=2.171875
INFO - Difference from standard: L2=28.375000, relative=1.609929 (160.99%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_008_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_008_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_008_vid005
INFO - Stored aggregated attention map for 'POC' from 20 steps
INFO - Attention storage completed for video: prompt_008_vid005
INFO - Attention tokens stored: ['POC']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_008/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_008/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_008/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['POC']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_008/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_008_vid005
INFO - âœ… Found exact matching video for prompt_008_vid005: outputs/ceo_20250925_111341/videos/prompt_008/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_008_vid005
INFO - Processing attention video for prompt_008_vid005:POC
INFO - Generating step-by-step attention video for prompt_008_vid005:POC
INFO - Loading aggregated attention for prompt_008_vid005:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid005/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid005/token_POC/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid005/token_POC/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_008_vid005:POC
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid005/token_POC
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid005/token_POC/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_008/vid005/token_POC/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_008_vid005: 1/1 successful
Generating videos: 46/80 (57.5%) - ETA: 1:34:31 - Medium shot of a professional (asian:5) ceo sittinINFO - Generating video 46/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_009_vid001
INFO - Attention storage enabled for video ID: prompt_009_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_009_vid001
INFO - Attention storage enabled for video: prompt_009_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'asian': 5.0}
INFO - Original prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_009_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_009/vid_001
INFO - Mapped target word 'asian' -> 'asian' -> tokens [289, 44714, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_009_vid001
INFO - Prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Target words specified: ['asian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'asian' -> tokens [289, 44714, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_009_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000002, std=0.020386, min=-3.781250, max=2.375000
INFO - Difference from standard: L2=19.000000, relative=1.048276 (104.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.91s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.91s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_009_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_009_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_009_vid001
INFO - Stored aggregated attention map for 'asian' from 20 steps
INFO - Attention storage completed for video: prompt_009_vid001
INFO - Attention tokens stored: ['asian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_009/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_009/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_009/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['asian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_009/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_009_vid001
INFO - âœ… Found exact matching video for prompt_009_vid001: outputs/ceo_20250925_111341/videos/prompt_009/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_009_vid001
INFO - Processing attention video for prompt_009_vid001:asian
INFO - Generating step-by-step attention video for prompt_009_vid001:asian
INFO - Loading aggregated attention for prompt_009_vid001:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid001/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid001/token_asian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid001/token_asian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_009_vid001:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid001/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid001/token_asian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid001/token_asian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_009_vid001: 1/1 successful
Generating videos: 47/80 (58.8%) - ETA: 1:31:46 - Medium shot of a professional (asian:5) ceo sittinINFO - Generating video 47/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_009_vid002
INFO - Attention storage enabled for video ID: prompt_009_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_009_vid002
INFO - Attention storage enabled for video: prompt_009_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'asian': 5.0}
INFO - Original prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_009_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_009/vid_002
INFO - Mapped target word 'asian' -> 'asian' -> tokens [289, 44714, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_009_vid002
INFO - Prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Target words specified: ['asian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'asian' -> tokens [289, 44714, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_009_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000002, std=0.020386, min=-3.781250, max=2.375000
INFO - Difference from standard: L2=19.000000, relative=1.048276 (104.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_009_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_009_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_009_vid002
INFO - Stored aggregated attention map for 'asian' from 20 steps
INFO - Attention storage completed for video: prompt_009_vid002
INFO - Attention tokens stored: ['asian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_009/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_009/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_009/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['asian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_009/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_009_vid002
INFO - âœ… Found exact matching video for prompt_009_vid002: outputs/ceo_20250925_111341/videos/prompt_009/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_009_vid002
INFO - Processing attention video for prompt_009_vid002:asian
INFO - Generating step-by-step attention video for prompt_009_vid002:asian
INFO - Loading aggregated attention for prompt_009_vid002:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid002/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid002/token_asian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid002/token_asian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_009_vid002:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid002/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid002/token_asian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid002/token_asian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_009_vid002: 1/1 successful
Generating videos: 48/80 (60.0%) - ETA: 1:29:00 - Medium shot of a professional (asian:5) ceo sittinINFO - Generating video 48/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_009_vid003
INFO - Attention storage enabled for video ID: prompt_009_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_009_vid003
INFO - Attention storage enabled for video: prompt_009_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'asian': 5.0}
INFO - Original prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_009_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_009/vid_003
INFO - Mapped target word 'asian' -> 'asian' -> tokens [289, 44714, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_009_vid003
INFO - Prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Target words specified: ['asian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'asian' -> tokens [289, 44714, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_009_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000002, std=0.020386, min=-3.781250, max=2.375000
INFO - Difference from standard: L2=19.000000, relative=1.048276 (104.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_009_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_009_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_009_vid003
INFO - Stored aggregated attention map for 'asian' from 20 steps
INFO - Attention storage completed for video: prompt_009_vid003
INFO - Attention tokens stored: ['asian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_009/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_009/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_009/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['asian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_009/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_009_vid003
INFO - âœ… Found exact matching video for prompt_009_vid003: outputs/ceo_20250925_111341/videos/prompt_009/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_009_vid003
INFO - Processing attention video for prompt_009_vid003:asian
INFO - Generating step-by-step attention video for prompt_009_vid003:asian
INFO - Loading aggregated attention for prompt_009_vid003:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid003/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid003/token_asian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid003/token_asian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_009_vid003:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid003/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid003/token_asian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid003/token_asian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_009_vid003: 1/1 successful
Generating videos: 49/80 (61.3%) - ETA: 1:26:15 - Medium shot of a professional (asian:5) ceo sittinINFO - Generating video 49/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_009_vid004
INFO - Attention storage enabled for video ID: prompt_009_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_009_vid004
INFO - Attention storage enabled for video: prompt_009_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'asian': 5.0}
INFO - Original prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_009_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_009/vid_004
INFO - Mapped target word 'asian' -> 'asian' -> tokens [289, 44714, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_009_vid004
INFO - Prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Target words specified: ['asian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'asian' -> tokens [289, 44714, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_009_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000002, std=0.020386, min=-3.781250, max=2.375000
INFO - Difference from standard: L2=19.000000, relative=1.048276 (104.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_009_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_009_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_009_vid004
INFO - Stored aggregated attention map for 'asian' from 20 steps
INFO - Attention storage completed for video: prompt_009_vid004
INFO - Attention tokens stored: ['asian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_009/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_009/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_009/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['asian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_009/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_009_vid004
INFO - âœ… Found exact matching video for prompt_009_vid004: outputs/ceo_20250925_111341/videos/prompt_009/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_009_vid004
INFO - Processing attention video for prompt_009_vid004:asian
INFO - Generating step-by-step attention video for prompt_009_vid004:asian
INFO - Loading aggregated attention for prompt_009_vid004:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid004/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid004/token_asian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid004/token_asian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_009_vid004:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid004/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid004/token_asian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid004/token_asian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_009_vid004: 1/1 successful
Generating videos: 50/80 (62.5%) - ETA: 1:23:29 - Medium shot of a professional (asian:5) ceo sittinINFO - Generating video 50/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_009_vid005
INFO - Attention storage enabled for video ID: prompt_009_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_009_vid005
INFO - Attention storage enabled for video: prompt_009_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'asian': 5.0}
INFO - Original prompt: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_009_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_009/vid_005
INFO - Mapped target word 'asian' -> 'asian' -> tokens [289, 44714, 501] at positions [3, 5, 10]
INFO - Started attention storage for video: prompt_009_vid005
INFO - Prompt: Medium shot of a professional asian ceo sitting in an office chair
INFO - Target words specified: ['asian']
INFO - Found 1 target tokens for attention tracking:
INFO -   'asian' -> tokens [289, 44714, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_009_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (asian:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000002, std=0.020386, min=-3.781250, max=2.375000
INFO - Difference from standard: L2=19.000000, relative=1.048276 (104.83%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.87s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_009_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_009_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_009_vid005
INFO - Stored aggregated attention map for 'asian' from 20 steps
INFO - Attention storage completed for video: prompt_009_vid005
INFO - Attention tokens stored: ['asian']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_009/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_009/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_009/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['asian']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_009/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_009_vid005
INFO - âœ… Found exact matching video for prompt_009_vid005: outputs/ceo_20250925_111341/videos/prompt_009/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_009_vid005
INFO - Processing attention video for prompt_009_vid005:asian
INFO - Generating step-by-step attention video for prompt_009_vid005:asian
INFO - Loading aggregated attention for prompt_009_vid005:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid005/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid005/token_asian/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid005/token_asian/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_009_vid005:asian
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid005/token_asian
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid005/token_asian/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_009/vid005/token_asian/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_009_vid005: 1/1 successful
Generating videos: 51/80 (63.7%) - ETA: 1:20:43 - Medium shot of a professional (hispanic:5) ceo sitINFO - Generating video 51/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_010_vid001
INFO - Attention storage enabled for video ID: prompt_010_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_010_vid001
INFO - Attention storage enabled for video: prompt_010_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hispanic': 5.0}
INFO - Original prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_010_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_010/vid_001
INFO - Mapped target word 'hispanic' -> 'hispanic' -> tokens [289, 146326, 1931, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_010_vid001
INFO - Prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Target words specified: ['hispanic']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hispanic' -> tokens [289, 146326, 1931, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_010_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000004, std=0.021729, min=-3.875000, max=3.031250
INFO - Difference from standard: L2=21.000000, relative=1.166667 (116.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_010_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_010_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_010_vid001
INFO - Stored aggregated attention map for 'hispanic' from 20 steps
INFO - Attention storage completed for video: prompt_010_vid001
INFO - Attention tokens stored: ['hispanic']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_010/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_010/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_010/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['hispanic']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_010/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_010_vid001
INFO - âœ… Found exact matching video for prompt_010_vid001: outputs/ceo_20250925_111341/videos/prompt_010/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_010_vid001
INFO - Processing attention video for prompt_010_vid001:hispanic
INFO - Generating step-by-step attention video for prompt_010_vid001:hispanic
INFO - Loading aggregated attention for prompt_010_vid001:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid001/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid001/token_hispanic/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid001/token_hispanic/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_010_vid001:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid001/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid001/token_hispanic/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid001/token_hispanic/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_010_vid001: 1/1 successful
Generating videos: 52/80 (65.0%) - ETA: 1:17:57 - Medium shot of a professional (hispanic:5) ceo sitINFO - Generating video 52/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_010_vid002
INFO - Attention storage enabled for video ID: prompt_010_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_010_vid002
INFO - Attention storage enabled for video: prompt_010_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hispanic': 5.0}
INFO - Original prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_010_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_010/vid_002
INFO - Mapped target word 'hispanic' -> 'hispanic' -> tokens [289, 146326, 1931, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_010_vid002
INFO - Prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Target words specified: ['hispanic']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hispanic' -> tokens [289, 146326, 1931, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_010_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000004, std=0.021729, min=-3.875000, max=3.031250
INFO - Difference from standard: L2=21.000000, relative=1.166667 (116.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.87s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_010_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_010_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_010_vid002
INFO - Stored aggregated attention map for 'hispanic' from 20 steps
INFO - Attention storage completed for video: prompt_010_vid002
INFO - Attention tokens stored: ['hispanic']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_010/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_010/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_010/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['hispanic']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_010/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_010_vid002
INFO - âœ… Found exact matching video for prompt_010_vid002: outputs/ceo_20250925_111341/videos/prompt_010/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_010_vid002
INFO - Processing attention video for prompt_010_vid002:hispanic
INFO - Generating step-by-step attention video for prompt_010_vid002:hispanic
INFO - Loading aggregated attention for prompt_010_vid002:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid002/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid002/token_hispanic/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid002/token_hispanic/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_010_vid002:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid002/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid002/token_hispanic/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid002/token_hispanic/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_010_vid002: 1/1 successful
Generating videos: 53/80 (66.2%) - ETA: 1:15:11 - Medium shot of a professional (hispanic:5) ceo sitINFO - Generating video 53/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_010_vid003
INFO - Attention storage enabled for video ID: prompt_010_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_010_vid003
INFO - Attention storage enabled for video: prompt_010_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hispanic': 5.0}
INFO - Original prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_010_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_010/vid_003
INFO - Mapped target word 'hispanic' -> 'hispanic' -> tokens [289, 146326, 1931, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_010_vid003
INFO - Prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Target words specified: ['hispanic']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hispanic' -> tokens [289, 146326, 1931, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_010_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000004, std=0.021729, min=-3.875000, max=3.031250
INFO - Difference from standard: L2=21.000000, relative=1.166667 (116.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_010_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_010_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_010_vid003
INFO - Stored aggregated attention map for 'hispanic' from 20 steps
INFO - Attention storage completed for video: prompt_010_vid003
INFO - Attention tokens stored: ['hispanic']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_010/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_010/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_010/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['hispanic']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_010/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_010_vid003
INFO - âœ… Found exact matching video for prompt_010_vid003: outputs/ceo_20250925_111341/videos/prompt_010/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_010_vid003
INFO - Processing attention video for prompt_010_vid003:hispanic
INFO - Generating step-by-step attention video for prompt_010_vid003:hispanic
INFO - Loading aggregated attention for prompt_010_vid003:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid003/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid003/token_hispanic/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid003/token_hispanic/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_010_vid003:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid003/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid003/token_hispanic/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid003/token_hispanic/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_010_vid003: 1/1 successful
Generating videos: 54/80 (67.5%) - ETA: 1:12:25 - Medium shot of a professional (hispanic:5) ceo sitINFO - Generating video 54/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_010_vid004
INFO - Attention storage enabled for video ID: prompt_010_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_010_vid004
INFO - Attention storage enabled for video: prompt_010_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hispanic': 5.0}
INFO - Original prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_010_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_010/vid_004
INFO - Mapped target word 'hispanic' -> 'hispanic' -> tokens [289, 146326, 1931, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_010_vid004
INFO - Prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Target words specified: ['hispanic']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hispanic' -> tokens [289, 146326, 1931, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_010_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000004, std=0.021729, min=-3.875000, max=3.031250
INFO - Difference from standard: L2=21.000000, relative=1.166667 (116.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.91s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.91s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.91s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:19<01:19,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.91s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_010_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_010_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_010_vid004
INFO - Stored aggregated attention map for 'hispanic' from 20 steps
INFO - Attention storage completed for video: prompt_010_vid004
INFO - Attention tokens stored: ['hispanic']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_010/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_010/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_010/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['hispanic']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_010/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_010_vid004
INFO - âœ… Found exact matching video for prompt_010_vid004: outputs/ceo_20250925_111341/videos/prompt_010/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_010_vid004
INFO - Processing attention video for prompt_010_vid004:hispanic
INFO - Generating step-by-step attention video for prompt_010_vid004:hispanic
INFO - Loading aggregated attention for prompt_010_vid004:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid004/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid004/token_hispanic/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid004/token_hispanic/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_010_vid004:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid004/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid004/token_hispanic/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid004/token_hispanic/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_010_vid004: 1/1 successful
Generating videos: 55/80 (68.8%) - ETA: 1:09:39 - Medium shot of a professional (hispanic:5) ceo sitINFO - Generating video 55/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_010_vid005
INFO - Attention storage enabled for video ID: prompt_010_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_010_vid005
INFO - Attention storage enabled for video: prompt_010_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hispanic': 5.0}
INFO - Original prompt: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_010_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_010/vid_005
INFO - Mapped target word 'hispanic' -> 'hispanic' -> tokens [289, 146326, 1931, 501] at positions [3, 5, 6, 11]
INFO - Started attention storage for video: prompt_010_vid005
INFO - Prompt: Medium shot of a professional hispanic ceo sitting in an office chair
INFO - Target words specified: ['hispanic']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hispanic' -> tokens [289, 146326, 1931, 501]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_010_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hispanic:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000004, std=0.021729, min=-3.875000, max=3.031250
INFO - Difference from standard: L2=21.000000, relative=1.166667 (116.67%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:19,  7.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:11,  7.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:22<00:15,  7.91s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:30<00:07,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:38<00:00,  7.90s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_010_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_010_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_010_vid005
INFO - Stored aggregated attention map for 'hispanic' from 20 steps
INFO - Attention storage completed for video: prompt_010_vid005
INFO - Attention tokens stored: ['hispanic']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_010/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_010/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_010/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['hispanic']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_010/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_010_vid005
INFO - âœ… Found exact matching video for prompt_010_vid005: outputs/ceo_20250925_111341/videos/prompt_010/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_010_vid005
INFO - Processing attention video for prompt_010_vid005:hispanic
INFO - Generating step-by-step attention video for prompt_010_vid005:hispanic
INFO - Loading aggregated attention for prompt_010_vid005:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid005/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid005/token_hispanic/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid005/token_hispanic/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_010_vid005:hispanic
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid005/token_hispanic
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid005/token_hispanic/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_010/vid005/token_hispanic/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_010_vid005: 1/1 successful
Generating videos: 56/80 (70.0%) - ETA: 1:06:53 - Medium shot of a professional (arab:5) ceo sittingINFO - Generating video 56/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_011_vid001
INFO - Attention storage enabled for video ID: prompt_011_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_011_vid001
INFO - Attention storage enabled for video: prompt_011_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'arab': 5.0}
INFO - Original prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_011_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_011/vid_001
INFO - Mapped target word 'arab' -> 'arab' -> tokens [289, 37316] at positions [3, 5]
INFO - Started attention storage for video: prompt_011_vid001
INFO - Prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Target words specified: ['arab']
INFO - Found 1 target tokens for attention tracking:
INFO -   'arab' -> tokens [289, 37316]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_011_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000007, std=0.018921, min=-3.671875, max=1.804688
INFO - Difference from standard: L2=17.125000, relative=0.978571 (97.86%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.87s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_011_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_011_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_011_vid001
INFO - Stored aggregated attention map for 'arab' from 20 steps
INFO - Attention storage completed for video: prompt_011_vid001
INFO - Attention tokens stored: ['arab']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_011/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_011/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_011/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['arab']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_011/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_011_vid001
INFO - âœ… Found exact matching video for prompt_011_vid001: outputs/ceo_20250925_111341/videos/prompt_011/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_011_vid001
INFO - Processing attention video for prompt_011_vid001:arab
INFO - Generating step-by-step attention video for prompt_011_vid001:arab
INFO - Loading aggregated attention for prompt_011_vid001:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid001/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid001/token_arab/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid001/token_arab/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_011_vid001:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid001/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid001/token_arab/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid001/token_arab/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_011_vid001: 1/1 successful
Generating videos: 57/80 (71.2%) - ETA: 1:04:06 - Medium shot of a professional (arab:5) ceo sittingINFO - Generating video 57/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_011_vid002
INFO - Attention storage enabled for video ID: prompt_011_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_011_vid002
INFO - Attention storage enabled for video: prompt_011_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'arab': 5.0}
INFO - Original prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_011_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_011/vid_002
INFO - Mapped target word 'arab' -> 'arab' -> tokens [289, 37316] at positions [3, 5]
INFO - Started attention storage for video: prompt_011_vid002
INFO - Prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Target words specified: ['arab']
INFO - Found 1 target tokens for attention tracking:
INFO -   'arab' -> tokens [289, 37316]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_011_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000007, std=0.018921, min=-3.671875, max=1.804688
INFO - Difference from standard: L2=17.125000, relative=0.978571 (97.86%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:30,  7.90s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_011_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_011_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_011_vid002
INFO - Stored aggregated attention map for 'arab' from 20 steps
INFO - Attention storage completed for video: prompt_011_vid002
INFO - Attention tokens stored: ['arab']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_011/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_011/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_011/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['arab']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_011/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_011_vid002
INFO - âœ… Found exact matching video for prompt_011_vid002: outputs/ceo_20250925_111341/videos/prompt_011/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_011_vid002
INFO - Processing attention video for prompt_011_vid002:arab
INFO - Generating step-by-step attention video for prompt_011_vid002:arab
INFO - Loading aggregated attention for prompt_011_vid002:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid002/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid002/token_arab/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid002/token_arab/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_011_vid002:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid002/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid002/token_arab/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid002/token_arab/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_011_vid002: 1/1 successful
Generating videos: 58/80 (72.5%) - ETA: 1:01:20 - Medium shot of a professional (arab:5) ceo sittingINFO - Generating video 58/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_011_vid003
INFO - Attention storage enabled for video ID: prompt_011_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_011_vid003
INFO - Attention storage enabled for video: prompt_011_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'arab': 5.0}
INFO - Original prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_011_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_011/vid_003
INFO - Mapped target word 'arab' -> 'arab' -> tokens [289, 37316] at positions [3, 5]
INFO - Started attention storage for video: prompt_011_vid003
INFO - Prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Target words specified: ['arab']
INFO - Found 1 target tokens for attention tracking:
INFO -   'arab' -> tokens [289, 37316]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_011_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000007, std=0.018921, min=-3.671875, max=1.804688
INFO - Difference from standard: L2=17.125000, relative=0.978571 (97.86%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.90s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.90s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:11<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.87s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_011_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_011_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_011_vid003
INFO - Stored aggregated attention map for 'arab' from 20 steps
INFO - Attention storage completed for video: prompt_011_vid003
INFO - Attention tokens stored: ['arab']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_011/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_011/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_011/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['arab']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_011/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_011_vid003
INFO - âœ… Found exact matching video for prompt_011_vid003: outputs/ceo_20250925_111341/videos/prompt_011/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_011_vid003
INFO - Processing attention video for prompt_011_vid003:arab
INFO - Generating step-by-step attention video for prompt_011_vid003:arab
INFO - Loading aggregated attention for prompt_011_vid003:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid003/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid003/token_arab/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid003/token_arab/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_011_vid003:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid003/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid003/token_arab/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid003/token_arab/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_011_vid003: 1/1 successful
Generating videos: 59/80 (73.8%) - ETA: 0:58:33 - Medium shot of a professional (arab:5) ceo sittingINFO - Generating video 59/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_011_vid004
INFO - Attention storage enabled for video ID: prompt_011_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_011_vid004
INFO - Attention storage enabled for video: prompt_011_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'arab': 5.0}
INFO - Original prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_011_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_011/vid_004
INFO - Mapped target word 'arab' -> 'arab' -> tokens [289, 37316] at positions [3, 5]
INFO - Started attention storage for video: prompt_011_vid004
INFO - Prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Target words specified: ['arab']
INFO - Found 1 target tokens for attention tracking:
INFO -   'arab' -> tokens [289, 37316]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_011_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000007, std=0.018921, min=-3.671875, max=1.804688
INFO - Difference from standard: L2=17.125000, relative=0.978571 (97.86%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.87s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_011_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_011_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_011_vid004
INFO - Stored aggregated attention map for 'arab' from 20 steps
INFO - Attention storage completed for video: prompt_011_vid004
INFO - Attention tokens stored: ['arab']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_011/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_011/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_011/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['arab']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_011/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_011_vid004
INFO - âœ… Found exact matching video for prompt_011_vid004: outputs/ceo_20250925_111341/videos/prompt_011/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_011_vid004
INFO - Processing attention video for prompt_011_vid004:arab
INFO - Generating step-by-step attention video for prompt_011_vid004:arab
INFO - Loading aggregated attention for prompt_011_vid004:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid004/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid004/token_arab/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid004/token_arab/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_011_vid004:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid004/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid004/token_arab/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid004/token_arab/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_011_vid004: 1/1 successful
Generating videos: 60/80 (75.0%) - ETA: 0:55:46 - Medium shot of a professional (arab:5) ceo sittingINFO - Generating video 60/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_011_vid005
INFO - Attention storage enabled for video ID: prompt_011_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_011_vid005
INFO - Attention storage enabled for video: prompt_011_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'arab': 5.0}
INFO - Original prompt: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_011_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_011/vid_005
INFO - Mapped target word 'arab' -> 'arab' -> tokens [289, 37316] at positions [3, 5]
INFO - Started attention storage for video: prompt_011_vid005
INFO - Prompt: Medium shot of a professional arab ceo sitting in an office chair
INFO - Target words specified: ['arab']
INFO - Found 1 target tokens for attention tracking:
INFO -   'arab' -> tokens [289, 37316]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_011_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (arab:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000007, std=0.018921, min=-3.671875, max=1.804688
INFO - Difference from standard: L2=17.125000, relative=0.978571 (97.86%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_011_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_011_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_011_vid005
INFO - Stored aggregated attention map for 'arab' from 20 steps
INFO - Attention storage completed for video: prompt_011_vid005
INFO - Attention tokens stored: ['arab']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_011/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_011/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_011/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['arab']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_011/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_011_vid005
INFO - âœ… Found exact matching video for prompt_011_vid005: outputs/ceo_20250925_111341/videos/prompt_011/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_011_vid005
INFO - Processing attention video for prompt_011_vid005:arab
INFO - Generating step-by-step attention video for prompt_011_vid005:arab
INFO - Loading aggregated attention for prompt_011_vid005:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid005/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid005/token_arab/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid005/token_arab/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_011_vid005:arab
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid005/token_arab
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid005/token_arab/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_011/vid005/token_arab/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_011_vid005: 1/1 successful
Generating videos: 61/80 (76.2%) - ETA: 0:52:59 - Medium shot of a professional (jewish:5) ceo sittiINFO - Generating video 61/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_012_vid001
INFO - Attention storage enabled for video ID: prompt_012_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_012_vid001
INFO - Attention storage enabled for video: prompt_012_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'jewish': 5.0}
INFO - Original prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_012_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_012/vid_001
INFO - Mapped target word 'jewish' -> 'jewish' -> tokens [360, 82234] at positions [5, 6]
INFO - Started attention storage for video: prompt_012_vid001
INFO - Prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Target words specified: ['jewish']
INFO - Found 1 target tokens for attention tracking:
INFO -   'jewish' -> tokens [360, 82234]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_012_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.028076, min=-4.031250, max=2.500000
INFO - Difference from standard: L2=29.125000, relative=1.484076 (148.41%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.86s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.86s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.86s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_012_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_012_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_012_vid001
INFO - Stored aggregated attention map for 'jewish' from 20 steps
INFO - Attention storage completed for video: prompt_012_vid001
INFO - Attention tokens stored: ['jewish']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_012/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_012/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_012/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['jewish']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_012/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_012_vid001
INFO - âœ… Found exact matching video for prompt_012_vid001: outputs/ceo_20250925_111341/videos/prompt_012/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_012_vid001
INFO - Processing attention video for prompt_012_vid001:jewish
INFO - Generating step-by-step attention video for prompt_012_vid001:jewish
INFO - Loading aggregated attention for prompt_012_vid001:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid001/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid001/token_jewish/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid001/token_jewish/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_012_vid001:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid001/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid001/token_jewish/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid001/token_jewish/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_012_vid001: 1/1 successful
Generating videos: 62/80 (77.5%) - ETA: 0:50:12 - Medium shot of a professional (jewish:5) ceo sittiINFO - Generating video 62/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_012_vid002
INFO - Attention storage enabled for video ID: prompt_012_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_012_vid002
INFO - Attention storage enabled for video: prompt_012_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'jewish': 5.0}
INFO - Original prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_012_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_012/vid_002
INFO - Mapped target word 'jewish' -> 'jewish' -> tokens [360, 82234] at positions [5, 6]
INFO - Started attention storage for video: prompt_012_vid002
INFO - Prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Target words specified: ['jewish']
INFO - Found 1 target tokens for attention tracking:
INFO -   'jewish' -> tokens [360, 82234]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_012_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.028076, min=-4.031250, max=2.500000
INFO - Difference from standard: L2=29.125000, relative=1.484076 (148.41%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.87s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.86s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.86s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:54,  7.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.86s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_012_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_012_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_012_vid002
INFO - Stored aggregated attention map for 'jewish' from 20 steps
INFO - Attention storage completed for video: prompt_012_vid002
INFO - Attention tokens stored: ['jewish']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_012/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_012/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_012/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['jewish']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_012/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_012_vid002
INFO - âœ… Found exact matching video for prompt_012_vid002: outputs/ceo_20250925_111341/videos/prompt_012/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_012_vid002
INFO - Processing attention video for prompt_012_vid002:jewish
INFO - Generating step-by-step attention video for prompt_012_vid002:jewish
INFO - Loading aggregated attention for prompt_012_vid002:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid002/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid002/token_jewish/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid002/token_jewish/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_012_vid002:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid002/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid002/token_jewish/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid002/token_jewish/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_012_vid002: 1/1 successful
Generating videos: 63/80 (78.8%) - ETA: 0:47:25 - Medium shot of a professional (jewish:5) ceo sittiINFO - Generating video 63/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_012_vid003
INFO - Attention storage enabled for video ID: prompt_012_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_012_vid003
INFO - Attention storage enabled for video: prompt_012_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'jewish': 5.0}
INFO - Original prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_012_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_012/vid_003
INFO - Mapped target word 'jewish' -> 'jewish' -> tokens [360, 82234] at positions [5, 6]
INFO - Started attention storage for video: prompt_012_vid003
INFO - Prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Target words specified: ['jewish']
INFO - Found 1 target tokens for attention tracking:
INFO -   'jewish' -> tokens [360, 82234]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_012_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.028076, min=-4.031250, max=2.500000
INFO - Difference from standard: L2=29.125000, relative=1.484076 (148.41%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.86s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.86s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.86s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.85s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.86s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_012_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_012_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_012_vid003
INFO - Stored aggregated attention map for 'jewish' from 20 steps
INFO - Attention storage completed for video: prompt_012_vid003
INFO - Attention tokens stored: ['jewish']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_012/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_012/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_012/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['jewish']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_012/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_012_vid003
INFO - âœ… Found exact matching video for prompt_012_vid003: outputs/ceo_20250925_111341/videos/prompt_012/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_012_vid003
INFO - Processing attention video for prompt_012_vid003:jewish
INFO - Generating step-by-step attention video for prompt_012_vid003:jewish
INFO - Loading aggregated attention for prompt_012_vid003:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid003/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid003/token_jewish/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid003/token_jewish/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_012_vid003:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid003/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid003/token_jewish/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid003/token_jewish/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_012_vid003: 1/1 successful
Generating videos: 64/80 (80.0%) - ETA: 0:44:38 - Medium shot of a professional (jewish:5) ceo sittiINFO - Generating video 64/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_012_vid004
INFO - Attention storage enabled for video ID: prompt_012_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_012_vid004
INFO - Attention storage enabled for video: prompt_012_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'jewish': 5.0}
INFO - Original prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_012_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_012/vid_004
INFO - Mapped target word 'jewish' -> 'jewish' -> tokens [360, 82234] at positions [5, 6]
INFO - Started attention storage for video: prompt_012_vid004
INFO - Prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Target words specified: ['jewish']
INFO - Found 1 target tokens for attention tracking:
INFO -   'jewish' -> tokens [360, 82234]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_012_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.028076, min=-4.031250, max=2.500000
INFO - Difference from standard: L2=29.125000, relative=1.484076 (148.41%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.86s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.86s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.86s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_012_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_012_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_012_vid004
INFO - Stored aggregated attention map for 'jewish' from 20 steps
INFO - Attention storage completed for video: prompt_012_vid004
INFO - Attention tokens stored: ['jewish']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_012/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_012/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_012/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['jewish']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_012/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_012_vid004
INFO - âœ… Found exact matching video for prompt_012_vid004: outputs/ceo_20250925_111341/videos/prompt_012/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_012_vid004
INFO - Processing attention video for prompt_012_vid004:jewish
INFO - Generating step-by-step attention video for prompt_012_vid004:jewish
INFO - Loading aggregated attention for prompt_012_vid004:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid004/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid004/token_jewish/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid004/token_jewish/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_012_vid004:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid004/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid004/token_jewish/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid004/token_jewish/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_012_vid004: 1/1 successful
Generating videos: 65/80 (81.2%) - ETA: 0:41:51 - Medium shot of a professional (jewish:5) ceo sittiINFO - Generating video 65/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_012_vid005
INFO - Attention storage enabled for video ID: prompt_012_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_012_vid005
INFO - Attention storage enabled for video: prompt_012_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'jewish': 5.0}
INFO - Original prompt: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_012_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_012/vid_005
INFO - Mapped target word 'jewish' -> 'jewish' -> tokens [360, 82234] at positions [5, 6]
INFO - Started attention storage for video: prompt_012_vid005
INFO - Prompt: Medium shot of a professional jewish ceo sitting in an office chair
INFO - Target words specified: ['jewish']
INFO - Found 1 target tokens for attention tracking:
INFO -   'jewish' -> tokens [360, 82234]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_012_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (jewish:5) ceo sitting in an office chair
INFO - Full sequence length: 15, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.016
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.028076, min=-4.031250, max=2.500000
INFO - Difference from standard: L2=29.125000, relative=1.484076 (148.41%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.86s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_012_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_012_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_012_vid005
INFO - Stored aggregated attention map for 'jewish' from 20 steps
INFO - Attention storage completed for video: prompt_012_vid005
INFO - Attention tokens stored: ['jewish']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_012/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_012/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_012/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['jewish']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_012/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_012_vid005
INFO - âœ… Found exact matching video for prompt_012_vid005: outputs/ceo_20250925_111341/videos/prompt_012/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_012_vid005
INFO - Processing attention video for prompt_012_vid005:jewish
INFO - Generating step-by-step attention video for prompt_012_vid005:jewish
INFO - Loading aggregated attention for prompt_012_vid005:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid005/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid005/token_jewish/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid005/token_jewish/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_012_vid005:jewish
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid005/token_jewish
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid005/token_jewish/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_012/vid005/token_jewish/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_012_vid005: 1/1 successful
Generating videos: 66/80 (82.5%) - ETA: 0:39:04 - Medium shot of a professional (muslim:5) ceo sittiINFO - Generating video 66/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_013_vid001
INFO - Attention storage enabled for video ID: prompt_013_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_013_vid001
INFO - Attention storage enabled for video: prompt_013_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'muslim': 5.0}
INFO - Original prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_013_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_013/vid_001
INFO - Mapped target word 'muslim' -> 'muslim' -> tokens [76949] at positions [5]
INFO - Started attention storage for video: prompt_013_vid001
INFO - Prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Target words specified: ['muslim']
INFO - Found 1 target tokens for attention tracking:
INFO -   'muslim' -> tokens [76949]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_013_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000010, std=0.018555, min=-4.093750, max=2.250000
INFO - Difference from standard: L2=16.375000, relative=0.909722 (90.97%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.85s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.86s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.85s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.85s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:49,  7.85s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:54<01:42,  7.85s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.85s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.85s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.85s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.85s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.85s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:54,  7.84s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:49<00:47,  7.84s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_013_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_013_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_013_vid001
INFO - Stored aggregated attention map for 'muslim' from 20 steps
INFO - Attention storage completed for video: prompt_013_vid001
INFO - Attention tokens stored: ['muslim']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_013/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_013/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_013/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['muslim']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_013/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_013_vid001
INFO - âœ… Found exact matching video for prompt_013_vid001: outputs/ceo_20250925_111341/videos/prompt_013/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_013_vid001
INFO - Processing attention video for prompt_013_vid001:muslim
INFO - Generating step-by-step attention video for prompt_013_vid001:muslim
INFO - Loading aggregated attention for prompt_013_vid001:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid001/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid001/token_muslim/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid001/token_muslim/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_013_vid001:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid001/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid001/token_muslim/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid001/token_muslim/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_013_vid001: 1/1 successful
Generating videos: 67/80 (83.8%) - ETA: 0:36:16 - Medium shot of a professional (muslim:5) ceo sittiINFO - Generating video 67/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_013_vid002
INFO - Attention storage enabled for video ID: prompt_013_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_013_vid002
INFO - Attention storage enabled for video: prompt_013_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'muslim': 5.0}
INFO - Original prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_013_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_013/vid_002
INFO - Mapped target word 'muslim' -> 'muslim' -> tokens [76949] at positions [5]
INFO - Started attention storage for video: prompt_013_vid002
INFO - Prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Target words specified: ['muslim']
INFO - Found 1 target tokens for attention tracking:
INFO -   'muslim' -> tokens [76949]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_013_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000010, std=0.018555, min=-4.093750, max=2.250000
INFO - Difference from standard: L2=16.375000, relative=0.909722 (90.97%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:28,  7.84s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.86s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.86s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.85s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:49,  7.84s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:54<01:42,  7.85s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.85s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.85s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.85s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.85s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.85s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:54,  7.85s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:49<00:47,  7.85s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_013_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_013_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_013_vid002
INFO - Stored aggregated attention map for 'muslim' from 20 steps
INFO - Attention storage completed for video: prompt_013_vid002
INFO - Attention tokens stored: ['muslim']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_013/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_013/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_013/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['muslim']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_013/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_013_vid002
INFO - âœ… Found exact matching video for prompt_013_vid002: outputs/ceo_20250925_111341/videos/prompt_013/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_013_vid002
INFO - Processing attention video for prompt_013_vid002:muslim
INFO - Generating step-by-step attention video for prompt_013_vid002:muslim
INFO - Loading aggregated attention for prompt_013_vid002:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid002/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid002/token_muslim/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid002/token_muslim/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_013_vid002:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid002/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid002/token_muslim/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid002/token_muslim/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_013_vid002: 1/1 successful
Generating videos: 68/80 (85.0%) - ETA: 0:33:29 - Medium shot of a professional (muslim:5) ceo sittiINFO - Generating video 68/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_013_vid003
INFO - Attention storage enabled for video ID: prompt_013_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_013_vid003
INFO - Attention storage enabled for video: prompt_013_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'muslim': 5.0}
INFO - Original prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_013_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_013/vid_003
INFO - Mapped target word 'muslim' -> 'muslim' -> tokens [76949] at positions [5]
INFO - Started attention storage for video: prompt_013_vid003
INFO - Prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Target words specified: ['muslim']
INFO - Found 1 target tokens for attention tracking:
INFO -   'muslim' -> tokens [76949]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_013_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000010, std=0.018555, min=-4.093750, max=2.250000
INFO - Difference from standard: L2=16.375000, relative=0.909722 (90.97%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.87s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.86s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.87s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.85s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:54,  7.85s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.85s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_013_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_013_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_013_vid003
INFO - Stored aggregated attention map for 'muslim' from 20 steps
INFO - Attention storage completed for video: prompt_013_vid003
INFO - Attention tokens stored: ['muslim']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_013/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_013/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_013/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['muslim']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_013/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_013_vid003
INFO - âœ… Found exact matching video for prompt_013_vid003: outputs/ceo_20250925_111341/videos/prompt_013/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_013_vid003
INFO - Processing attention video for prompt_013_vid003:muslim
INFO - Generating step-by-step attention video for prompt_013_vid003:muslim
INFO - Loading aggregated attention for prompt_013_vid003:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid003/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid003/token_muslim/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid003/token_muslim/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_013_vid003:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid003/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid003/token_muslim/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid003/token_muslim/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_013_vid003: 1/1 successful
Generating videos: 69/80 (86.2%) - ETA: 0:30:42 - Medium shot of a professional (muslim:5) ceo sittiINFO - Generating video 69/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_013_vid004
INFO - Attention storage enabled for video ID: prompt_013_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_013_vid004
INFO - Attention storage enabled for video: prompt_013_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'muslim': 5.0}
INFO - Original prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_013_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_013/vid_004
INFO - Mapped target word 'muslim' -> 'muslim' -> tokens [76949] at positions [5]
INFO - Started attention storage for video: prompt_013_vid004
INFO - Prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Target words specified: ['muslim']
INFO - Found 1 target tokens for attention tracking:
INFO -   'muslim' -> tokens [76949]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_013_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000010, std=0.018555, min=-4.093750, max=2.250000
INFO - Difference from standard: L2=16.375000, relative=0.909722 (90.97%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.87s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.85s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.85s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.85s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:54,  7.85s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:49<00:47,  7.85s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_013_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_013_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_013_vid004
INFO - Stored aggregated attention map for 'muslim' from 20 steps
INFO - Attention storage completed for video: prompt_013_vid004
INFO - Attention tokens stored: ['muslim']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_013/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_013/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_013/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['muslim']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_013/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_013_vid004
INFO - âœ… Found exact matching video for prompt_013_vid004: outputs/ceo_20250925_111341/videos/prompt_013/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_013_vid004
INFO - Processing attention video for prompt_013_vid004:muslim
INFO - Generating step-by-step attention video for prompt_013_vid004:muslim
INFO - Loading aggregated attention for prompt_013_vid004:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid004/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid004/token_muslim/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid004/token_muslim/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_013_vid004:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid004/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid004/token_muslim/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid004/token_muslim/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_013_vid004: 1/1 successful
Generating videos: 70/80 (87.5%) - ETA: 0:27:54 - Medium shot of a professional (muslim:5) ceo sittiINFO - Generating video 70/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_013_vid005
INFO - Attention storage enabled for video ID: prompt_013_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_013_vid005
INFO - Attention storage enabled for video: prompt_013_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'muslim': 5.0}
INFO - Original prompt: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_013_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_013/vid_005
INFO - Mapped target word 'muslim' -> 'muslim' -> tokens [76949] at positions [5]
INFO - Started attention storage for video: prompt_013_vid005
INFO - Prompt: Medium shot of a professional muslim ceo sitting in an office chair
INFO - Target words specified: ['muslim']
INFO - Found 1 target tokens for attention tracking:
INFO -   'muslim' -> tokens [76949]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_013_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (muslim:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000010, std=0.018555, min=-4.093750, max=2.250000
INFO - Difference from standard: L2=16.375000, relative=0.909722 (90.97%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.85s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.85s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.85s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.85s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:49,  7.85s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:54<01:42,  7.85s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.85s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.85s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.85s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.85s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.85s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:54,  7.85s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:49<00:47,  7.85s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.85s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_013_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_013_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_013_vid005
INFO - Stored aggregated attention map for 'muslim' from 20 steps
INFO - Attention storage completed for video: prompt_013_vid005
INFO - Attention tokens stored: ['muslim']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_013/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_013/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_013/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['muslim']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_013/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_013_vid005
INFO - âœ… Found exact matching video for prompt_013_vid005: outputs/ceo_20250925_111341/videos/prompt_013/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_013_vid005
INFO - Processing attention video for prompt_013_vid005:muslim
INFO - Generating step-by-step attention video for prompt_013_vid005:muslim
INFO - Loading aggregated attention for prompt_013_vid005:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid005/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid005/token_muslim/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid005/token_muslim/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_013_vid005:muslim
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid005/token_muslim
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid005/token_muslim/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_013/vid005/token_muslim/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_013_vid005: 1/1 successful
Generating videos: 71/80 (88.8%) - ETA: 0:25:07 - Medium shot of a professional (hindu:5) ceo sittinINFO - Generating video 71/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_014_vid001
INFO - Attention storage enabled for video ID: prompt_014_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_014_vid001
INFO - Attention storage enabled for video: prompt_014_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hindu': 5.0}
INFO - Original prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_014_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_014/vid_001
INFO - Mapped target word 'hindu' -> 'hindu' -> tokens [146490, 301] at positions [5, 9]
INFO - Started attention storage for video: prompt_014_vid001
INFO - Prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Target words specified: ['hindu']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hindu' -> tokens [146490, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_014_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.020996, min=-3.906250, max=1.890625
INFO - Difference from standard: L2=20.125000, relative=1.133803 (113.38%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:54,  7.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.86s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_014_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_014_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_014_vid001
INFO - Stored aggregated attention map for 'hindu' from 20 steps
INFO - Attention storage completed for video: prompt_014_vid001
INFO - Attention tokens stored: ['hindu']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_014/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_014/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_014/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['hindu']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_014/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_014_vid001
INFO - âœ… Found exact matching video for prompt_014_vid001: outputs/ceo_20250925_111341/videos/prompt_014/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_014_vid001
INFO - Processing attention video for prompt_014_vid001:hindu
INFO - Generating step-by-step attention video for prompt_014_vid001:hindu
INFO - Loading aggregated attention for prompt_014_vid001:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid001/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid001/token_hindu/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid001/token_hindu/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_014_vid001:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid001/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid001/token_hindu/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid001/token_hindu/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_014_vid001: 1/1 successful
Generating videos: 72/80 (90.0%) - ETA: 0:22:20 - Medium shot of a professional (hindu:5) ceo sittinINFO - Generating video 72/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_014_vid002
INFO - Attention storage enabled for video ID: prompt_014_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_014_vid002
INFO - Attention storage enabled for video: prompt_014_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hindu': 5.0}
INFO - Original prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_014_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_014/vid_002
INFO - Mapped target word 'hindu' -> 'hindu' -> tokens [146490, 301] at positions [5, 9]
INFO - Started attention storage for video: prompt_014_vid002
INFO - Prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Target words specified: ['hindu']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hindu' -> tokens [146490, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_014_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.020996, min=-3.906250, max=1.890625
INFO - Difference from standard: L2=20.125000, relative=1.133803 (113.38%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.86s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.86s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.86s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:57,  7.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.86s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_014_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_014_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_014_vid002
INFO - Stored aggregated attention map for 'hindu' from 20 steps
INFO - Attention storage completed for video: prompt_014_vid002
INFO - Attention tokens stored: ['hindu']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_014/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_014/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_014/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['hindu']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_014/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_014_vid002
INFO - âœ… Found exact matching video for prompt_014_vid002: outputs/ceo_20250925_111341/videos/prompt_014/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_014_vid002
INFO - Processing attention video for prompt_014_vid002:hindu
INFO - Generating step-by-step attention video for prompt_014_vid002:hindu
INFO - Loading aggregated attention for prompt_014_vid002:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid002/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid002/token_hindu/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid002/token_hindu/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_014_vid002:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid002/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid002/token_hindu/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid002/token_hindu/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_014_vid002: 1/1 successful
Generating videos: 73/80 (91.2%) - ETA: 0:19:32 - Medium shot of a professional (hindu:5) ceo sittinINFO - Generating video 73/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_014_vid003
INFO - Attention storage enabled for video ID: prompt_014_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_014_vid003
INFO - Attention storage enabled for video: prompt_014_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hindu': 5.0}
INFO - Original prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_014_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_014/vid_003
INFO - Mapped target word 'hindu' -> 'hindu' -> tokens [146490, 301] at positions [5, 9]
INFO - Started attention storage for video: prompt_014_vid003
INFO - Prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Target words specified: ['hindu']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hindu' -> tokens [146490, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_014_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.020996, min=-3.906250, max=1.890625
INFO - Difference from standard: L2=20.125000, relative=1.133803 (113.38%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.85s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_014_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_014_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_014_vid003
INFO - Stored aggregated attention map for 'hindu' from 20 steps
INFO - Attention storage completed for video: prompt_014_vid003
INFO - Attention tokens stored: ['hindu']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_014/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_014/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_014/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['hindu']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_014/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_014_vid003
INFO - âœ… Found exact matching video for prompt_014_vid003: outputs/ceo_20250925_111341/videos/prompt_014/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_014_vid003
INFO - Processing attention video for prompt_014_vid003:hindu
INFO - Generating step-by-step attention video for prompt_014_vid003:hindu
INFO - Loading aggregated attention for prompt_014_vid003:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid003/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid003/token_hindu/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid003/token_hindu/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_014_vid003:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid003/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid003/token_hindu/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid003/token_hindu/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_014_vid003: 1/1 successful
Generating videos: 74/80 (92.5%) - ETA: 0:16:45 - Medium shot of a professional (hindu:5) ceo sittinINFO - Generating video 74/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_014_vid004
INFO - Attention storage enabled for video ID: prompt_014_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_014_vid004
INFO - Attention storage enabled for video: prompt_014_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hindu': 5.0}
INFO - Original prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_014_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_014/vid_004
INFO - Mapped target word 'hindu' -> 'hindu' -> tokens [146490, 301] at positions [5, 9]
INFO - Started attention storage for video: prompt_014_vid004
INFO - Prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Target words specified: ['hindu']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hindu' -> tokens [146490, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_014_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.020996, min=-3.906250, max=1.890625
INFO - Difference from standard: L2=20.125000, relative=1.133803 (113.38%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:14<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_014_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_014_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_014_vid004
INFO - Stored aggregated attention map for 'hindu' from 20 steps
INFO - Attention storage completed for video: prompt_014_vid004
INFO - Attention tokens stored: ['hindu']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_014/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_014/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_014/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['hindu']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_014/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_014_vid004
INFO - âœ… Found exact matching video for prompt_014_vid004: outputs/ceo_20250925_111341/videos/prompt_014/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_014_vid004
INFO - Processing attention video for prompt_014_vid004:hindu
INFO - Generating step-by-step attention video for prompt_014_vid004:hindu
INFO - Loading aggregated attention for prompt_014_vid004:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid004/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid004/token_hindu/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid004/token_hindu/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_014_vid004:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid004/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid004/token_hindu/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid004/token_hindu/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_014_vid004: 1/1 successful
Generating videos: 75/80 (93.8%) - ETA: 0:13:57 - Medium shot of a professional (hindu:5) ceo sittinINFO - Generating video 75/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_014_vid005
INFO - Attention storage enabled for video ID: prompt_014_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_014_vid005
INFO - Attention storage enabled for video: prompt_014_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'hindu': 5.0}
INFO - Original prompt: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_014_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_014/vid_005
INFO - Mapped target word 'hindu' -> 'hindu' -> tokens [146490, 301] at positions [5, 9]
INFO - Started attention storage for video: prompt_014_vid005
INFO - Prompt: Medium shot of a professional hindu ceo sitting in an office chair
INFO - Target words specified: ['hindu']
INFO - Found 1 target tokens for attention tracking:
INFO -   'hindu' -> tokens [146490, 301]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_014_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (hindu:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=0.000012, std=0.020996, min=-3.906250, max=1.890625
INFO - Difference from standard: L2=20.125000, relative=1.133803 (113.38%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_014_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_014_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_014_vid005
INFO - Stored aggregated attention map for 'hindu' from 20 steps
INFO - Attention storage completed for video: prompt_014_vid005
INFO - Attention tokens stored: ['hindu']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_014/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_014/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_014/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['hindu']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_014/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_014_vid005
INFO - âœ… Found exact matching video for prompt_014_vid005: outputs/ceo_20250925_111341/videos/prompt_014/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_014_vid005
INFO - Processing attention video for prompt_014_vid005:hindu
INFO - Generating step-by-step attention video for prompt_014_vid005:hindu
INFO - Loading aggregated attention for prompt_014_vid005:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid005/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid005/token_hindu/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid005/token_hindu/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_014_vid005:hindu
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid005/token_hindu
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid005/token_hindu/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_014/vid005/token_hindu/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_014_vid005: 1/1 successful
Generating videos: 76/80 (95.0%) - ETA: 0:11:10 - Medium shot of a professional (disabled:5) ceo sitINFO - Generating video 76/80: video_001
INFO - Using seed: 999 (base: 999 + video_num: 0)
INFO - Latent storage enabled for video ID: prompt_015_vid001
INFO - Attention storage enabled for video ID: prompt_015_vid001
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Seed: 999
INFO - Latent storage enabled for video: prompt_015_vid001
INFO - Attention storage enabled for video: prompt_015_vid001
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'disabled': 5.0}
INFO - Original prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_015_vid001
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_015/vid_001
INFO - Mapped target word 'disabled' -> 'disabled' -> tokens [289, 127363] at positions [3, 5]
INFO - Started attention storage for video: prompt_015_vid001
INFO - Prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Target words specified: ['disabled']
INFO - Found 1 target tokens for attention tracking:
INFO -   'disabled' -> tokens [289, 127363]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_015_vid001
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.017456, min=-4.031250, max=2.468750
INFO - Difference from standard: L2=14.625000, relative=0.823944 (82.39%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.88s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_015_vid001: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_015_vid001: 20 steps stored
INFO - Generating aggregated attention maps for prompt_015_vid001
INFO - Stored aggregated attention map for 'disabled' from 20 steps
INFO - Attention storage completed for video: prompt_015_vid001
INFO - Attention tokens stored: ['disabled']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_015/video_001.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_015/video_001.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_015/video_001.mp4
INFO - Attention storage: 1 tokens tracked: ['disabled']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_015/video_001.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_015_vid001
INFO - âœ… Found exact matching video for prompt_015_vid001: outputs/ceo_20250925_111341/videos/prompt_015/video_001.mp4
INFO - âœ… Video path verification passed: video_001.mp4 matches prompt_015_vid001
INFO - Processing attention video for prompt_015_vid001:disabled
INFO - Generating step-by-step attention video for prompt_015_vid001:disabled
INFO - Loading aggregated attention for prompt_015_vid001:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid001/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid001/token_disabled/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid001/token_disabled/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_015_vid001:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid001/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid001/token_disabled/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid001/token_disabled/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_015_vid001: 1/1 successful
Generating videos: 77/80 (96.2%) - ETA: 0:08:22 - Medium shot of a professional (disabled:5) ceo sitINFO - Generating video 77/80: video_002
INFO - Using seed: 1000 (base: 999 + video_num: 1)
INFO - Latent storage enabled for video ID: prompt_015_vid002
INFO - Attention storage enabled for video ID: prompt_015_vid002
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Seed: 1000
INFO - Latent storage enabled for video: prompt_015_vid002
INFO - Attention storage enabled for video: prompt_015_vid002
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'disabled': 5.0}
INFO - Original prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_015_vid002
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_015/vid_002
INFO - Mapped target word 'disabled' -> 'disabled' -> tokens [289, 127363] at positions [3, 5]
INFO - Started attention storage for video: prompt_015_vid002
INFO - Prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Target words specified: ['disabled']
INFO - Found 1 target tokens for attention tracking:
INFO -   'disabled' -> tokens [289, 127363]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_015_vid002
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.017456, min=-4.031250, max=2.468750
INFO - Difference from standard: L2=14.625000, relative=0.823944 (82.39%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.89s/it] 10%|â–ˆ         | 2/20 [00:15<02:22,  7.89s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:14,  7.89s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.87s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.87s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:06<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_015_vid002: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_015_vid002: 20 steps stored
INFO - Generating aggregated attention maps for prompt_015_vid002
INFO - Stored aggregated attention map for 'disabled' from 20 steps
INFO - Attention storage completed for video: prompt_015_vid002
INFO - Attention tokens stored: ['disabled']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_015/video_002.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_015/video_002.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_015/video_002.mp4
INFO - Attention storage: 1 tokens tracked: ['disabled']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_015/video_002.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_015_vid002
INFO - âœ… Found exact matching video for prompt_015_vid002: outputs/ceo_20250925_111341/videos/prompt_015/video_002.mp4
INFO - âœ… Video path verification passed: video_002.mp4 matches prompt_015_vid002
INFO - Processing attention video for prompt_015_vid002:disabled
INFO - Generating step-by-step attention video for prompt_015_vid002:disabled
INFO - Loading aggregated attention for prompt_015_vid002:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid002/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid002/token_disabled/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid002/token_disabled/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_015_vid002:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid002/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid002/token_disabled/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid002/token_disabled/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_015_vid002: 1/1 successful
Generating videos: 78/80 (97.5%) - ETA: 0:05:35 - Medium shot of a professional (disabled:5) ceo sitINFO - Generating video 78/80: video_003
INFO - Using seed: 1001 (base: 999 + video_num: 2)
INFO - Latent storage enabled for video ID: prompt_015_vid003
INFO - Attention storage enabled for video ID: prompt_015_vid003
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Seed: 1001
INFO - Latent storage enabled for video: prompt_015_vid003
INFO - Attention storage enabled for video: prompt_015_vid003
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'disabled': 5.0}
INFO - Original prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_015_vid003
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_015/vid_003
INFO - Mapped target word 'disabled' -> 'disabled' -> tokens [289, 127363] at positions [3, 5]
INFO - Started attention storage for video: prompt_015_vid003
INFO - Prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Target words specified: ['disabled']
INFO - Found 1 target tokens for attention tracking:
INFO -   'disabled' -> tokens [289, 127363]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_015_vid003
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.017456, min=-4.031250, max=2.468750
INFO - Difference from standard: L2=14.625000, relative=0.823944 (82.39%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.87s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.87s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_015_vid003: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_015_vid003: 20 steps stored
INFO - Generating aggregated attention maps for prompt_015_vid003
INFO - Stored aggregated attention map for 'disabled' from 20 steps
INFO - Attention storage completed for video: prompt_015_vid003
INFO - Attention tokens stored: ['disabled']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_015/video_003.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_015/video_003.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_015/video_003.mp4
INFO - Attention storage: 1 tokens tracked: ['disabled']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_015/video_003.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_015_vid003
INFO - âœ… Found exact matching video for prompt_015_vid003: outputs/ceo_20250925_111341/videos/prompt_015/video_003.mp4
INFO - âœ… Video path verification passed: video_003.mp4 matches prompt_015_vid003
INFO - Processing attention video for prompt_015_vid003:disabled
INFO - Generating step-by-step attention video for prompt_015_vid003:disabled
INFO - Loading aggregated attention for prompt_015_vid003:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid003/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid003/token_disabled/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid003/token_disabled/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_015_vid003:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid003/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid003/token_disabled/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid003/token_disabled/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_015_vid003: 1/1 successful
Generating videos: 79/80 (98.8%) - ETA: 0:02:47 - Medium shot of a professional (disabled:5) ceo sitINFO - Generating video 79/80: video_004
INFO - Using seed: 1002 (base: 999 + video_num: 3)
INFO - Latent storage enabled for video ID: prompt_015_vid004
INFO - Attention storage enabled for video ID: prompt_015_vid004
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Seed: 1002
INFO - Latent storage enabled for video: prompt_015_vid004
INFO - Attention storage enabled for video: prompt_015_vid004
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'disabled': 5.0}
INFO - Original prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_015_vid004
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_015/vid_004
INFO - Mapped target word 'disabled' -> 'disabled' -> tokens [289, 127363] at positions [3, 5]
INFO - Started attention storage for video: prompt_015_vid004
INFO - Prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Target words specified: ['disabled']
INFO - Found 1 target tokens for attention tracking:
INFO -   'disabled' -> tokens [289, 127363]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_015_vid004
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.017456, min=-4.031250, max=2.468750
INFO - Difference from standard: L2=14.625000, relative=0.823944 (82.39%)
ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:29,  7.88s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.87s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.88s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:06,  7.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:03<01:34,  7.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:03,  7.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:58<00:39,  7.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_015_vid004: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_015_vid004: 20 steps stored
INFO - Generating aggregated attention maps for prompt_015_vid004
INFO - Stored aggregated attention map for 'disabled' from 20 steps
INFO - Attention storage completed for video: prompt_015_vid004
INFO - Attention tokens stored: ['disabled']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_015/video_004.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_015/video_004.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_015/video_004.mp4
INFO - Attention storage: 1 tokens tracked: ['disabled']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_015/video_004.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_015_vid004
INFO - âœ… Found exact matching video for prompt_015_vid004: outputs/ceo_20250925_111341/videos/prompt_015/video_004.mp4
INFO - âœ… Video path verification passed: video_004.mp4 matches prompt_015_vid004
INFO - Processing attention video for prompt_015_vid004:disabled
INFO - Generating step-by-step attention video for prompt_015_vid004:disabled
INFO - Loading aggregated attention for prompt_015_vid004:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid004/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid004/token_disabled/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid004/token_disabled/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_015_vid004:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid004/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid004/token_disabled/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid004/token_disabled/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_015_vid004: 1/1 successful
Generating videos: 80/80 (100.0%) - ETA: 0:00:00 - Medium shot of a professional (disabled:5) ceo sitINFO - Generating video 80/80: video_005
INFO - Using seed: 1003 (base: 999 + video_num: 4)
INFO - Latent storage enabled for video ID: prompt_015_vid005
INFO - Attention storage enabled for video ID: prompt_015_vid005
INFO - ðŸŽ¯ Using guidance_scale from config: 6.5
INFO - Generating video: 848x480, 61 frames
INFO - Prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Seed: 1003
INFO - Latent storage enabled for video: prompt_015_vid005
INFO - Attention storage enabled for video: prompt_015_vid005
INFO - GPU memory before generation: 33.6GB free on cuda:1
INFO - Prompt weights detected: {'disabled': 5.0}
INFO - Original prompt: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Processed prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Using WAN weighted embeddings for generation
INFO - Captured 20 timesteps from scheduler
INFO - Captured 21 sigmas from scheduler
INFO - ðŸš« Dynamic guidance disabled: enabled=False, schedule={}
INFO - Starting latent storage for video: prompt_015_vid005
INFO - Latents will be stored in: outputs/ceo_20250925_111341/latents/prompt_015/vid_005
INFO - Mapped target word 'disabled' -> 'disabled' -> tokens [289, 127363] at positions [3, 5]
INFO - Started attention storage for video: prompt_015_vid005
INFO - Prompt: Medium shot of a professional disabled ceo sitting in an office chair
INFO - Target words specified: ['disabled']
INFO - Found 1 target tokens for attention tracking:
INFO -   'disabled' -> tokens [289, 127363]
INFO - Found transformer model for attention hooks: WanTransformer3DModel
INFO - âœ… Successfully wrapped 30 attn2 modules with WanAttentionWrapper
INFO - Registered attention hooks on transformer for video: prompt_015_vid005
INFO - âœ… Created combined callback with guidance_callback=False
INFO - ðŸŽ¯ Using static guidance scale: 6.5
INFO - Creating T5 weighted embeddings for: Medium shot of a professional (disabled:5) ceo sitting in an office chair
INFO - Full sequence length: 14, Max length: 512
INFO - Base embeddings shape: torch.Size([1, 512, 4096])
INFO - Token weights applied: min=1.000, max=5.000, mean=1.008
INFO - Applying weights using method: multiply
INFO - Embeddings shape: torch.Size([1, 512, 4096]), Weights shape: torch.Size([512])
INFO - Final weighted embeddings shape: torch.Size([1, 512, 4096])
INFO - Weighted embeddings stats: mean=-0.000009, std=0.017456, min=-4.031250, max=2.468750
INFO - Difference from standard: L2=14.625000, relative=0.823944 (82.39%)

ensure_cfg_for_schedule False
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:07<02:28,  7.84s/it] 10%|â–ˆ         | 2/20 [00:15<02:21,  7.86s/it] 15%|â–ˆâ–Œ        | 3/20 [00:23<02:13,  7.87s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:31<02:05,  7.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:39<01:58,  7.87s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:47<01:50,  7.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:55<01:42,  7.87s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:02<01:34,  7.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:10<01:26,  7.86s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:18<01:18,  7.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:26<01:10,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:34<01:02,  7.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:42<00:55,  7.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:50<00:47,  7.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:57<00:39,  7.86s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:05<00:31,  7.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:13<00:23,  7.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:21<00:15,  7.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:29<00:07,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:37<00:00,  7.87s/it]
INFO - Successfully generated video using weighted embeddings
INFO - Finished storing latents for prompt_015_vid005: 20 steps stored
INFO - Latent storage completed: 20 steps stored
INFO - Restored 30 original attn2 modules
INFO - Removed attention hooks from transformer
INFO - Finished storing attention maps for prompt_015_vid005: 20 steps stored
INFO - Generating aggregated attention maps for prompt_015_vid005
INFO - Stored aggregated attention map for 'disabled' from 20 steps
INFO - Attention storage completed for video: prompt_015_vid005
INFO - Attention tokens stored: ['disabled']
INFO - Video frames type: <class 'numpy.ndarray'>
INFO - Video frames length: 61
INFO - First frame type: <class 'numpy.ndarray'>
INFO - Moved all video frames to CPU for export
INFO - Exporting video frames to: outputs/ceo_20250925_111341/videos/prompt_015/video_005.mp4
INFO - Video export completed successfully
INFO - Generating thumbnail for: outputs/ceo_20250925_111341/videos/prompt_015/video_005.mp4
INFO - Thumbnail generated successfully
INFO - GPU memory after export: 33.6GB free on device 1
INFO - Successfully generated: outputs/ceo_20250925_111341/videos/prompt_015/video_005.mp4
INFO - Attention storage: 1 tokens tracked: ['disabled']
INFO - âœ… Video file verified at outputs/ceo_20250925_111341/videos/prompt_015/video_005.mp4, proceeding with attention video generation
INFO - Generating attention videos for completed video: prompt_015_vid005
INFO - âœ… Found exact matching video for prompt_015_vid005: outputs/ceo_20250925_111341/videos/prompt_015/video_005.mp4
INFO - âœ… Video path verification passed: video_005.mp4 matches prompt_015_vid005
INFO - Processing attention video for prompt_015_vid005:disabled
INFO - Generating step-by-step attention video for prompt_015_vid005:disabled
INFO - Loading aggregated attention for prompt_015_vid005:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_overlay.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid005/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid005/token_disabled/aggregate_overlay.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid005/token_disabled/aggregate_overlay.mp4 (61 frames, 480Ã—848)
INFO - Loading aggregated attention for prompt_015_vid005:disabled
INFO - Generated aggregated attention: shape=torch.Size([25440, 1])
INFO - After squeeze: spatial_attention.shape=torch.Size([25440])
INFO - Using metadata from first step: 0
INFO - Final spatial_attention: shape=torch.Size([25440]), dtype=torch.float16
INFO - Reshaping attention: spatial_size=25440, expected=25440
INFO - Original spatial_attention shape: torch.Size([25440])
INFO - Latent dimensions: frames=16, height=30, width=53
INFO - Perfect reshape match: torch.Size([16, 30, 53])
INFO - Converted to numpy: shape=(16, 30, 53), dtype=float16
INFO - Attention latent shape: (16, 30, 53) -> Target: 61Ã—480Ã—848
INFO - AttentionVisualizer received output_filename: 'aggregate_attention.mp4'
INFO - AttentionVisualizer self.output_dir: 'outputs/ceo_20250925_111341/attention_videos'
INFO - Creating attention video directory: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid005/token_disabled
INFO - Final output path: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid005/token_disabled/aggregate_attention.mp4
INFO - Generated attention video: outputs/ceo_20250925_111341/attention_videos/prompt_015/vid005/token_disabled/aggregate_attention.mp4 (61 frames, 480Ã—848)
INFO - âœ… Generated attention video: aggregate_attention.mp4
INFO - âœ… Generated attention video: aggregate_overlay.mp4
INFO - ðŸŽ¬ Attention video generation complete for prompt_015_vid005: 1/1 successful
INFO - Generation Summary:
INFO -   Total videos: 80
INFO -   Successful: 80
INFO -   Failed: 0
INFO -   Success rate: 100.0%
INFO -   Total time: 13501.9s
INFO -   Avg time per video: 168.8s
INFO - Latent Storage Summary:
INFO -   Total videos with latents: 80
INFO -   Total latent files: 3280
INFO -   Total storage size: 4562.1 MB
INFO - Attention Storage Summary:
INFO -   Attention maps stored in: outputs/ceo_20250925_111341/attention_maps
INFO -   Target tokens processed for each video
INFO - Batch complete! Results saved to: outputs/ceo_20250925_111341

Video generation complete in 3:46:20

ðŸŽ‰ Batch generation complete!
Results saved to: outputs/ceo_20250925_111341
