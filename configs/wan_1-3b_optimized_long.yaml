# Optimized configuration for WAN 2.1 14B model with aggressive memory management

# Model-specific settings
model_settings:
  seed: 999                    # Random seed for reproducibility
  sampler: "unipc"             # Scheduler type (unipc recommended for WAN)
  cfg_scale: 6.5               # Classifier-free guidance scale
  steps: 20                    # Number of inference steps
  eta: 0.0                     # Scheduler eta parameter
  clip_skip: 1                 # CLIP skip layers
  model_id: "Wan-AI/Wan2.1-T2V-1.3B-Diffusers"  # 14B model

# Aggressive memory optimization settings for 14B model
memory_settings:
  enable_memory_optimization: true    # Enable all memory optimizations
  clear_cache_between_videos: true    # Aggressively clear GPU cache between videos
  reload_model_for_large_models: true # Reload model between videos to prevent memory accumulation
  use_gradient_checkpointing: true    # Enable gradient checkpointing (saves ~30% memory)
  enable_memory_efficient_attention: true  # Enable memory efficient attention if available

# Video generation parameters (conservative settings for memory)
video_settings:
  width: 848                 # Video width (must be divisible by 8)
  height: 480                # Video height (must be divisible by 8) - lower than 720p to save memory
  fps: 12                    # Frames per second
  duration: 5             # Video duration in seconds
  frames: null                  # Total frames (calculated from fps * duration if null)

# Batch settings (smaller batches for memory management)
videos_per_variation: 8      # Fewer videos per variation to reduce memory pressure
output_dir: "outputs"        # Base output directory
batch_name: null             # Optional batch name (timestamp used if null)
use_timestamp: true          # Add timestamp to batch directory name

# Prompt weighting configuration - ENABLE WEIGHTED EMBEDDINGS
prompt_settings:
  enable_weighting: false                   # DISABLE auto-weighting (using manual weights instead)
  variation_weight: 1.0                     # Not used when enable_weighting is false
  base_weight: 1.0                          # Standard weight for base prompt
  
  # Advanced weighted embeddings (WORKING SYSTEM)
  use_weighted_embeddings: true             # Enable WAN-specific weighted embeddings
  embedding_method: "multiply"              # "multiply", "interpolation", or "norm_preserving"



# Latent trajectory analysis settings
latent_analysis_settings:
  store_latents: true                       # Enable latent storage
  latent_storage_format: "numpy"           # "numpy" or "torch"
  storage_interval: 1                      # Store every N steps (1 = all steps)
  compress_latents: true                   # Use gzip compression
  storage_dtype: "float16"                 # "float32" or "float16" (FP16 saves ~50% storage)


# Attention map analysis settings
attention_analysis_settings:
  store_attention: false                    # Enable attention map storage
  tokenizer_name: "google/umt5-xxl"        # T5 tokenizer used by WAN pipeline
  storage_format: "numpy"                  # "numpy" or "torch"
  compress_attention: true                 # Use gzip compression
  storage_interval: 1                      # Store every 2 steps (attention maps are larger)
  storage_dtype: "float16"                 # Use FP16 for memory efficiency
  
  # Advanced settings (normally keep false for basic usage)
  store_per_head: false                    # Store individual attention heads
  store_per_block: false                   # Store individual transformer blocks
  store_individual_tokens: false          # Store individual token attention
  attention_threshold: 0.01                # Filter out weak attention values
  spatial_downsample_factor: 2             # Downsample spatial dimensions 2x
